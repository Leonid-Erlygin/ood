{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_resnet50 = torchvision.models.wide_resnet50_2(pretrained=False).to(device)\n",
    "wide_resnet50.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/workspaces/ood/data/models/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\"\n",
    "    )\n",
    ")\n",
    "\n",
    "for name, param in wide_resnet50.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"cifar10train\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 1000\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to ../data/feature_maps/cifar10train_wide_resnet50_layer2_layer3_layer4_1000_img_per_class.npz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      " 21%|██▏       | 10716/50000 [01:53<06:54, 94.76it/s] \n"
     ]
    }
   ],
   "source": [
    "create_feature_dataset(\n",
    "    model=wide_resnet50,\n",
    "    layers=layers,\n",
    "    out_dims=out_dims,\n",
    "    dataset=cifar_data_train,\n",
    "    num_images_per_class=num_images_per_class,\n",
    "    out_name=out_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1215/10000 [00:11<01:22, 106.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes are computed\n",
      "saving to ../data/feature_maps/cifar10test_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz...\n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"cifar10test\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 100\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")\n",
    "\n",
    "create_feature_dataset(\n",
    "    model=wide_resnet50,\n",
    "    layers=layers,\n",
    "    out_dims=out_dims,\n",
    "    dataset=cifar_data_test,\n",
    "    num_images_per_class=num_images_per_class,\n",
    "    out_name=out_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1215/10000 [00:12<01:27, 100.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes are computed\n",
      "saving to ../data/feature_maps/svhntest_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz...\n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"svhntest\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 100\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")\n",
    "\n",
    "create_feature_dataset(\n",
    "    model=wide_resnet50,\n",
    "    layers=layers,\n",
    "    out_dims=out_dims,\n",
    "    dataset=cifar_data_test,\n",
    "    num_images_per_class=num_images_per_class,\n",
    "    out_name=out_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:05<00:00, 61.93s/it] \n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import split_layers\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"cifar10train\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 1000\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")\n",
    "split_layers(out_name, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(\n",
    "    \"/workspaces/ood/data/feature_maps/cifar10test_wide_resnet50_layer2_100_img_per_class.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature_extractor import FeatureExtractor\n",
    "# encoder = FeatureExtractor(wide_resnet50, layers)\n",
    "# encoder.eval()\n",
    "\n",
    "# preds = {layers[i] : np.zeros([num_images_per_class * 10]+out_dims[i], dtype=np.float32) for i in range(len(layers))}\n",
    "# label_counts = {i:0 for i in range(10)}\n",
    "# label_not_finish = [True for _ in range(10)]\n",
    "# i = 0\n",
    "# for image, label in tqdm(cifar_data_train):\n",
    "#     if i > 140:\n",
    "#         break\n",
    "#     if not any(label_not_finish):\n",
    "#         break\n",
    "#     if label_counts[label] >= num_images_per_class:\n",
    "#         label_not_finish[label] = False\n",
    "#         continue\n",
    "\n",
    "#     features = encoder(torch.unsqueeze(image.to(device), dim=0))\n",
    "#     for layer in features.keys():\n",
    "#         preds[layer][i] = features[layer].detach().cpu().numpy()[0]\n",
    "#     i+=1\n",
    "#     label_counts[label]+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
