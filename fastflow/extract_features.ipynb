{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_resnet50 = torchvision.models.wide_resnet50_2(pretrained=False).to(device)\n",
    "wide_resnet50.load_state_dict(torch.load('/workspaces/ood/data/models/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth'))\n",
    "\n",
    "for name, param in wide_resnet50.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "model_name = 'wide_resnet50'\n",
    "dataset_name = 'cifar10train'\n",
    "layers = ['layer2', 'layer3', 'layer4']\n",
    "out_dims = [[512,28,28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class=1000\n",
    "out_name = '../data/feature_maps/' + '_'.join([dataset_name] + [model_name] + layers) + f'_{num_images_per_class}_img_per_class.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to ../data/feature_maps/cifar10train_wide_resnet50_layer2_layer3_layer4_1000_img_per_class.npz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      " 21%|██▏       | 10716/50000 [01:53<06:54, 94.76it/s] \n"
     ]
    }
   ],
   "source": [
    "create_feature_dataset(model=wide_resnet50, layers=layers,out_dims=out_dims, dataset=cifar_data_train, num_images_per_class=num_images_per_class, out_name=out_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1215/10000 [00:11<01:22, 106.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes are computed\n",
      "saving to ../data/feature_maps/cifar10test_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz...\n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "model_name = 'wide_resnet50'\n",
    "dataset_name = 'cifar10test'\n",
    "layers = ['layer2', 'layer3', 'layer4']\n",
    "out_dims = [[512,28,28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class=100\n",
    "out_name = '../data/feature_maps/' + '_'.join([dataset_name] + [model_name] + layers) + f'_{num_images_per_class}_img_per_class.npz'\n",
    "\n",
    "create_feature_dataset(model=wide_resnet50, layers=layers,out_dims=out_dims, dataset=cifar_data_test, num_images_per_class=num_images_per_class, out_name=out_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1215/10000 [00:12<01:27, 100.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes are computed\n",
      "saving to ../data/feature_maps/svhntest_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz...\n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")\n",
    "\n",
    "model_name = 'wide_resnet50'\n",
    "dataset_name = 'svhntest'\n",
    "layers = ['layer2', 'layer3', 'layer4']\n",
    "out_dims = [[512,28,28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class=100\n",
    "out_name = '../data/feature_maps/' + '_'.join([dataset_name] + [model_name] + layers) + f'_{num_images_per_class}_img_per_class.npz'\n",
    "\n",
    "create_feature_dataset(model=wide_resnet50, layers=layers,out_dims=out_dims, dataset=cifar_data_test, num_images_per_class=num_images_per_class, out_name=out_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load('/workspaces/ood/data/feature_maps/cifar10test_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature_extractor import FeatureExtractor\n",
    "# encoder = FeatureExtractor(wide_resnet50, layers)\n",
    "# encoder.eval()\n",
    "\n",
    "# preds = {layers[i] : np.zeros([num_images_per_class * 10]+out_dims[i], dtype=np.float32) for i in range(len(layers))}\n",
    "# label_counts = {i:0 for i in range(10)}\n",
    "# label_not_finish = [True for _ in range(10)]\n",
    "# i = 0\n",
    "# for image, label in tqdm(cifar_data_train):\n",
    "#     if i > 140:\n",
    "#         break\n",
    "#     if not any(label_not_finish):\n",
    "#         break\n",
    "#     if label_counts[label] >= num_images_per_class:\n",
    "#         label_not_finish[label] = False\n",
    "#         continue\n",
    "\n",
    "#     features = encoder(torch.unsqueeze(image.to(device), dim=0))\n",
    "#     for layer in features.keys():\n",
    "#         preds[layer][i] = features[layer].detach().cpu().numpy()[0]\n",
    "#     i+=1\n",
    "#     label_counts[label]+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
