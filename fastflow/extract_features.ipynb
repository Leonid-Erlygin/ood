{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/package/_mock_zipreader.py:17: UserWarning: Failed to initialize NumPy: module compiled against API version 0xe but this version of numpy is 0xd (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:67.)\n",
      "  _dtype_to_storage = {data_type(0).dtype: data_type for data_type in _storages}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wide_resnet50 = torchvision.models.wide_resnet50_2(pretrained=False).to(device)\n",
    "wide_resnet50.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/workspaces/ood/data/models/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\"\n",
    "    )\n",
    ")\n",
    "\n",
    "for name, param in wide_resnet50.named_parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"cifar10train\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 100\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "  0%|          | 0/50000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7d78c504918e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m create_feature_dataset(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwide_resnet50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mout_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcifar_data_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspaces/ood/fastflow/extract_features.py\u001b[0m in \u001b[0;36mcreate_feature_dataset\u001b[0;34m(model, layers, out_dims, dataset, out_name, num_images_per_class, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "create_feature_dataset(\n",
    "    model=wide_resnet50,\n",
    "    layers=layers,\n",
    "    out_dims=out_dims,\n",
    "    dataset=cifar_data_train,\n",
    "    num_images_per_class=num_images_per_class,\n",
    "    out_name=out_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1215/10000 [00:11<01:22, 106.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes are computed\n",
      "saving to ../data/feature_maps/cifar10test_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz...\n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"cifar10test\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 100\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")\n",
    "\n",
    "create_feature_dataset(\n",
    "    model=wide_resnet50,\n",
    "    layers=layers,\n",
    "    out_dims=out_dims,\n",
    "    dataset=cifar_data_test,\n",
    "    num_images_per_class=num_images_per_class,\n",
    "    out_name=out_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1215/10000 [00:12<01:27, 100.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all classes are computed\n",
      "saving to ../data/feature_maps/svhntest_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npz...\n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import create_feature_dataset\n",
    "\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"svhntest\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 100\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")\n",
    "\n",
    "create_feature_dataset(\n",
    "    model=wide_resnet50,\n",
    "    layers=layers,\n",
    "    out_dims=out_dims,\n",
    "    dataset=cifar_data_test,\n",
    "    num_images_per_class=num_images_per_class,\n",
    "    out_name=out_name,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [03:05<00:00, 61.93s/it] \n"
     ]
    }
   ],
   "source": [
    "from fastflow.extract_features import split_layers\n",
    "\n",
    "model_name = \"wide_resnet50\"\n",
    "dataset_name = \"cifar10train\"\n",
    "layers = [\"layer2\", \"layer3\", \"layer4\"]\n",
    "out_dims = [[512, 28, 28], [1024, 14, 14], [2048, 7, 7]]\n",
    "num_images_per_class = 1000\n",
    "out_name = (\n",
    "    \"../data/feature_maps/\"\n",
    "    + \"_\".join([dataset_name] + [model_name] + layers)\n",
    "    + f\"_{num_images_per_class}_img_per_class.npz\"\n",
    ")\n",
    "split_layers(out_name, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.load(\n",
    "    \"/workspaces/ood/data/feature_maps/cifar10test_wide_resnet50_layer2_100_img_per_class.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from feature_extractor import FeatureExtractor\n",
    "# encoder = FeatureExtractor(wide_resnet50, layers)\n",
    "# encoder.eval()\n",
    "\n",
    "# preds = {layers[i] : np.zeros([num_images_per_class * 10]+out_dims[i], dtype=np.float32) for i in range(len(layers))}\n",
    "# label_counts = {i:0 for i in range(10)}\n",
    "# label_not_finish = [True for _ in range(10)]\n",
    "# i = 0\n",
    "# for image, label in tqdm(cifar_data_train):\n",
    "#     if i > 140:\n",
    "#         break\n",
    "#     if not any(label_not_finish):\n",
    "#         break\n",
    "#     if label_counts[label] >= num_images_per_class:\n",
    "#         label_not_finish[label] = False\n",
    "#         continue\n",
    "\n",
    "#     features = encoder(torch.unsqueeze(image.to(device), dim=0))\n",
    "#     for layer in features.keys():\n",
    "#         preds[layer][i] = features[layer].detach().cpu().numpy()[0]\n",
    "#     i+=1\n",
    "#     label_counts[label]+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
