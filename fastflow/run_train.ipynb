{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "from train import FastflowTrainer\n",
    "from omegaconf import OmegaConf\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from data import FeaturesTrainDataset, FeaturesDatasetOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"/workspaces/ood/fastflow/config.yaml\"\n",
    "cfg = OmegaConf.load(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 100\n",
    "train_dataset = FeaturesTrainDataset(\n",
    "    \"/workspaces/ood/data/feature_maps/cifar10train_wide_resnet50_layer2_layer3_layer4_1000_img_per_class.npy\",\n",
    "    [\"layer2\", \"layer3\", \"layer4\"],\n",
    "    [(train_size, 512, 28, 28), (train_size, 1024, 14, 14), (train_size, 2048, 7, 7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FeaturesDatasetOOD(\n",
    "    \"/workspaces/ood/data/feature_maps/cifar10test_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npy\",\n",
    "    \"/workspaces/ood/data/feature_maps/svhntest_wide_resnet50_layer2_layer3_layer4_100_img_per_class.npy\",\n",
    "    [\"layer2\", \"layer3\", \"layer4\"],\n",
    "    [(1000, 512, 28, 28), (1000, 1024, 14, 14), (1000, 2048, 7, 7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=cfg.trainer.batch_size, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=cfg.trainer.batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = FastflowTrainer(cfg)\n",
    "\n",
    "trainer.train(train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(trainer.model.state_dict(), f\"debug_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = FastflowTrainer(cfg)\n",
    "# trainer.model.load_state_dict(torch.load(\"debug_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import FastflowModel, get_logp\n",
    "\n",
    "\n",
    "# def make_predictions(model, dataset, device):\n",
    "#     \"\"\"\n",
    "#     returns logits for each samlple in dataset\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     preds_in = []\n",
    "#     preds_out = []\n",
    "\n",
    "#     for emb, label in tqdm(dataset):\n",
    "#         avg_loss = 0\n",
    "#         for layer_idx, encoder_activations in enumerate(emb):\n",
    "#             encoder_activations = torch.unsqueeze(\n",
    "#                 torch.tensor(encoder_activations).to(device), dim=0\n",
    "#             )\n",
    "#             (\n",
    "#                 _,\n",
    "#                 dim_feature_vector,\n",
    "#                 im_height,\n",
    "#                 im_width,\n",
    "#             ) = encoder_activations.size()\n",
    "#             decoder = model.decoders[layer_idx].to(device)\n",
    "#             p_u, log_jac_det = decoder(encoder_activations)\n",
    "#             print(log_jac_det, flush=True)\n",
    "#             return\n",
    "#             decoder_log_prob = get_logp(dim_feature_vector, p_u, log_jac_det)\n",
    "#             avg_loss += decoder_log_prob.sum().detach().cpu().numpy()\n",
    "#             print(p_u)\n",
    "#             return\n",
    "#         if label == 0:\n",
    "#             preds_in.append(avg_loss)\n",
    "#         elif label == 1:\n",
    "#             preds_out.append(avg_loss)\n",
    "#         else:\n",
    "#             raise ValueError\n",
    "#         print(preds_in, preds_out)\n",
    "#         return\n",
    "\n",
    "#     return preds_in, preds_out\n",
    "\n",
    "\n",
    "# preds = make_predictions(trainer.model, test_dataset, torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
