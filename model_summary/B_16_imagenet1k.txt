----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 768, 24, 24]         590,592
PositionalEmbedding1D-2             [-1, 577, 768]               0
         LayerNorm-3             [-1, 577, 768]           1,536
            Linear-4             [-1, 577, 768]         590,592
            Linear-5             [-1, 577, 768]         590,592
            Linear-6             [-1, 577, 768]         590,592
           Dropout-7         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-8             [-1, 577, 768]               0
            Linear-9             [-1, 577, 768]         590,592
          Dropout-10             [-1, 577, 768]               0
        LayerNorm-11             [-1, 577, 768]           1,536
           Linear-12            [-1, 577, 3072]       2,362,368
           Linear-13             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-14             [-1, 577, 768]               0
          Dropout-15             [-1, 577, 768]               0
            Block-16             [-1, 577, 768]               0
        LayerNorm-17             [-1, 577, 768]           1,536
           Linear-18             [-1, 577, 768]         590,592
           Linear-19             [-1, 577, 768]         590,592
           Linear-20             [-1, 577, 768]         590,592
          Dropout-21         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-22             [-1, 577, 768]               0
           Linear-23             [-1, 577, 768]         590,592
          Dropout-24             [-1, 577, 768]               0
        LayerNorm-25             [-1, 577, 768]           1,536
           Linear-26            [-1, 577, 3072]       2,362,368
           Linear-27             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-28             [-1, 577, 768]               0
          Dropout-29             [-1, 577, 768]               0
            Block-30             [-1, 577, 768]               0
        LayerNorm-31             [-1, 577, 768]           1,536
           Linear-32             [-1, 577, 768]         590,592
           Linear-33             [-1, 577, 768]         590,592
           Linear-34             [-1, 577, 768]         590,592
          Dropout-35         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-36             [-1, 577, 768]               0
           Linear-37             [-1, 577, 768]         590,592
          Dropout-38             [-1, 577, 768]               0
        LayerNorm-39             [-1, 577, 768]           1,536
           Linear-40            [-1, 577, 3072]       2,362,368
           Linear-41             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-42             [-1, 577, 768]               0
          Dropout-43             [-1, 577, 768]               0
            Block-44             [-1, 577, 768]               0
        LayerNorm-45             [-1, 577, 768]           1,536
           Linear-46             [-1, 577, 768]         590,592
           Linear-47             [-1, 577, 768]         590,592
           Linear-48             [-1, 577, 768]         590,592
          Dropout-49         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-50             [-1, 577, 768]               0
           Linear-51             [-1, 577, 768]         590,592
          Dropout-52             [-1, 577, 768]               0
        LayerNorm-53             [-1, 577, 768]           1,536
           Linear-54            [-1, 577, 3072]       2,362,368
           Linear-55             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-56             [-1, 577, 768]               0
          Dropout-57             [-1, 577, 768]               0
            Block-58             [-1, 577, 768]               0
        LayerNorm-59             [-1, 577, 768]           1,536
           Linear-60             [-1, 577, 768]         590,592
           Linear-61             [-1, 577, 768]         590,592
           Linear-62             [-1, 577, 768]         590,592
          Dropout-63         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-64             [-1, 577, 768]               0
           Linear-65             [-1, 577, 768]         590,592
          Dropout-66             [-1, 577, 768]               0
        LayerNorm-67             [-1, 577, 768]           1,536
           Linear-68            [-1, 577, 3072]       2,362,368
           Linear-69             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-70             [-1, 577, 768]               0
          Dropout-71             [-1, 577, 768]               0
            Block-72             [-1, 577, 768]               0
        LayerNorm-73             [-1, 577, 768]           1,536
           Linear-74             [-1, 577, 768]         590,592
           Linear-75             [-1, 577, 768]         590,592
           Linear-76             [-1, 577, 768]         590,592
          Dropout-77         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-78             [-1, 577, 768]               0
           Linear-79             [-1, 577, 768]         590,592
          Dropout-80             [-1, 577, 768]               0
        LayerNorm-81             [-1, 577, 768]           1,536
           Linear-82            [-1, 577, 3072]       2,362,368
           Linear-83             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-84             [-1, 577, 768]               0
          Dropout-85             [-1, 577, 768]               0
            Block-86             [-1, 577, 768]               0
        LayerNorm-87             [-1, 577, 768]           1,536
           Linear-88             [-1, 577, 768]         590,592
           Linear-89             [-1, 577, 768]         590,592
           Linear-90             [-1, 577, 768]         590,592
          Dropout-91         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-92             [-1, 577, 768]               0
           Linear-93             [-1, 577, 768]         590,592
          Dropout-94             [-1, 577, 768]               0
        LayerNorm-95             [-1, 577, 768]           1,536
           Linear-96            [-1, 577, 3072]       2,362,368
           Linear-97             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-98             [-1, 577, 768]               0
          Dropout-99             [-1, 577, 768]               0
           Block-100             [-1, 577, 768]               0
       LayerNorm-101             [-1, 577, 768]           1,536
          Linear-102             [-1, 577, 768]         590,592
          Linear-103             [-1, 577, 768]         590,592
          Linear-104             [-1, 577, 768]         590,592
         Dropout-105         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-106             [-1, 577, 768]               0
          Linear-107             [-1, 577, 768]         590,592
         Dropout-108             [-1, 577, 768]               0
       LayerNorm-109             [-1, 577, 768]           1,536
          Linear-110            [-1, 577, 3072]       2,362,368
          Linear-111             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-112             [-1, 577, 768]               0
         Dropout-113             [-1, 577, 768]               0
           Block-114             [-1, 577, 768]               0
       LayerNorm-115             [-1, 577, 768]           1,536
          Linear-116             [-1, 577, 768]         590,592
          Linear-117             [-1, 577, 768]         590,592
          Linear-118             [-1, 577, 768]         590,592
         Dropout-119         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-120             [-1, 577, 768]               0
          Linear-121             [-1, 577, 768]         590,592
         Dropout-122             [-1, 577, 768]               0
       LayerNorm-123             [-1, 577, 768]           1,536
          Linear-124            [-1, 577, 3072]       2,362,368
          Linear-125             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-126             [-1, 577, 768]               0
         Dropout-127             [-1, 577, 768]               0
           Block-128             [-1, 577, 768]               0
       LayerNorm-129             [-1, 577, 768]           1,536
          Linear-130             [-1, 577, 768]         590,592
          Linear-131             [-1, 577, 768]         590,592
          Linear-132             [-1, 577, 768]         590,592
         Dropout-133         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-134             [-1, 577, 768]               0
          Linear-135             [-1, 577, 768]         590,592
         Dropout-136             [-1, 577, 768]               0
       LayerNorm-137             [-1, 577, 768]           1,536
          Linear-138            [-1, 577, 3072]       2,362,368
          Linear-139             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-140             [-1, 577, 768]               0
         Dropout-141             [-1, 577, 768]               0
           Block-142             [-1, 577, 768]               0
       LayerNorm-143             [-1, 577, 768]           1,536
          Linear-144             [-1, 577, 768]         590,592
          Linear-145             [-1, 577, 768]         590,592
          Linear-146             [-1, 577, 768]         590,592
         Dropout-147         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-148             [-1, 577, 768]               0
          Linear-149             [-1, 577, 768]         590,592
         Dropout-150             [-1, 577, 768]               0
       LayerNorm-151             [-1, 577, 768]           1,536
          Linear-152            [-1, 577, 3072]       2,362,368
          Linear-153             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-154             [-1, 577, 768]               0
         Dropout-155             [-1, 577, 768]               0
           Block-156             [-1, 577, 768]               0
       LayerNorm-157             [-1, 577, 768]           1,536
          Linear-158             [-1, 577, 768]         590,592
          Linear-159             [-1, 577, 768]         590,592
          Linear-160             [-1, 577, 768]         590,592
         Dropout-161         [-1, 12, 577, 577]               0
MultiHeadedSelfAttention-162             [-1, 577, 768]               0
          Linear-163             [-1, 577, 768]         590,592
         Dropout-164             [-1, 577, 768]               0
       LayerNorm-165             [-1, 577, 768]           1,536
          Linear-166            [-1, 577, 3072]       2,362,368
          Linear-167             [-1, 577, 768]       2,360,064
PositionWiseFeedForward-168             [-1, 577, 768]               0
         Dropout-169             [-1, 577, 768]               0
           Block-170             [-1, 577, 768]               0
     Transformer-171             [-1, 577, 768]               0
       LayerNorm-172             [-1, 577, 768]           1,536
          Linear-173                 [-1, 1000]         769,000
================================================================
Total params: 86,415,592
Trainable params: 86,415,592
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 1.69
Forward/backward pass size (MB): 1028.42
Params size (MB): 329.65
Estimated Total Size (MB): 1359.75
----------------------------------------------------------------
