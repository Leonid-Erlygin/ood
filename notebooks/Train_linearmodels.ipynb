{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from scripts_ood.train import train_linear_model\n",
    "import warnings\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from scripts_ood.utils import imagenet_sanity_check\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import timm\n",
    "\n",
    "from scripts_ood.utils import load_pretrained_weights_vit\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'byol'\n",
    "# in_dist_data = 'svhn'\n",
    "# linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048, in_dist_data=in_dist_data, train_epoch=100, init_lr=1e-4)\n",
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_{in_dist_data}_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vit_base_patch16_384 no linear image net head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vit_base_patch16_384'\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=0).to(device)\n",
    "model.eval();\n",
    "model_name = 'vit_base_patch16_384_nohead'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "svhn_data_train = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform\n",
    ")\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions are already present in /workspaces/ood/data/predictions/vit_base_patch16_384_nohead_svhn_test.npy\n",
      "Predictions are already present in /workspaces/ood/data/predictions/vit_base_patch16_384_nohead_cifar_test.npy\n",
      "Predictions are already present in /workspaces/ood/data/predictions/vit_base_patch16_384_nohead_cifar_train.npy\n",
      "Predictions are already present in /workspaces/ood/data/predictions/vit_base_patch16_384_nohead_svhn_train.npy\n"
     ]
    }
   ],
   "source": [
    "from scripts_ood.utils import predict_on_whole_dataset\n",
    "\n",
    "\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 2.56401,  train_accuracy: 0.11248, test_accuracy 0.11056\n",
      "current LR: 0.0001\n",
      "epoch: 1, train loss: 1.71622,  train_accuracy: 0.41539, test_accuracy 0.42340\n",
      "current LR: 0.0001\n",
      "epoch: 2, train loss: 1.58441,  train_accuracy: 0.48563, test_accuracy 0.49985\n",
      "current LR: 0.0001\n",
      "epoch: 3, train loss: 1.51112,  train_accuracy: 0.51928, test_accuracy 0.53519\n",
      "current LR: 0.0001\n",
      "epoch: 4, train loss: 1.41367,  train_accuracy: 0.54152, test_accuracy 0.56054\n",
      "current LR: 0.0001\n",
      "epoch: 5, train loss: 1.38661,  train_accuracy: 0.55537, test_accuracy 0.57137\n",
      "current LR: 0.0001\n",
      "epoch: 6, train loss: 1.46041,  train_accuracy: 0.56588, test_accuracy 0.58313\n",
      "current LR: 0.0001\n",
      "epoch: 7, train loss: 1.35759,  train_accuracy: 0.57414, test_accuracy 0.59008\n",
      "current LR: 0.0001\n",
      "epoch: 8, train loss: 1.36534,  train_accuracy: 0.58228, test_accuracy 0.59577\n",
      "current LR: 0.0001\n",
      "epoch: 9, train loss: 1.34415,  train_accuracy: 0.58400, test_accuracy 0.60134\n",
      "current LR: 0.0001\n",
      "epoch: 10, train loss: 1.29809,  train_accuracy: 0.59078, test_accuracy 0.60556\n",
      "current LR: 0.0001\n",
      "epoch: 11, train loss: 1.35794,  train_accuracy: 0.59607, test_accuracy 0.60671\n",
      "current LR: 0.0001\n",
      "epoch: 12, train loss: 1.31660,  train_accuracy: 0.59795, test_accuracy 0.60825\n",
      "current LR: 0.0001\n",
      "epoch: 13, train loss: 1.29471,  train_accuracy: 0.59934, test_accuracy 0.60910\n",
      "current LR: 0.0001\n",
      "epoch: 14, train loss: 1.30949,  train_accuracy: 0.60016, test_accuracy 0.61067\n",
      "current LR: 0.0001\n",
      "epoch: 15, train loss: 1.27635,  train_accuracy: 0.60370, test_accuracy 0.61321\n",
      "current LR: 0.0001\n",
      "epoch: 16, train loss: 1.25501,  train_accuracy: 0.60479, test_accuracy 0.61374\n",
      "current LR: 0.0001\n",
      "epoch: 17, train loss: 1.29034,  train_accuracy: 0.60602, test_accuracy 0.61271\n",
      "current LR: 0.0001\n",
      "epoch: 18, train loss: 1.24053,  train_accuracy: 0.60816, test_accuracy 0.61494\n",
      "current LR: 0.0001\n",
      "epoch: 19, train loss: 1.19720,  train_accuracy: 0.60831, test_accuracy 0.61701\n",
      "current LR: 2.5e-05\n",
      "epoch: 20, train loss: 1.29020,  train_accuracy: 0.60955, test_accuracy 0.61755\n",
      "current LR: 5e-05\n",
      "epoch: 21, train loss: 1.28209,  train_accuracy: 0.61223, test_accuracy 0.61851\n",
      "current LR: 5e-05\n",
      "epoch: 22, train loss: 1.31574,  train_accuracy: 0.61157, test_accuracy 0.61647\n",
      "current LR: 5e-05\n",
      "epoch: 23, train loss: 1.24508,  train_accuracy: 0.61175, test_accuracy 0.61866\n",
      "current LR: 5e-05\n",
      "epoch: 24, train loss: 1.25058,  train_accuracy: 0.61381, test_accuracy 0.61885\n",
      "current LR: 5e-05\n",
      "epoch: 25, train loss: 1.21942,  train_accuracy: 0.61269, test_accuracy 0.62035\n",
      "current LR: 5e-05\n",
      "epoch: 26, train loss: 1.26522,  train_accuracy: 0.61217, test_accuracy 0.61855\n",
      "current LR: 5e-05\n",
      "epoch: 27, train loss: 1.23074,  train_accuracy: 0.61440, test_accuracy 0.61747\n",
      "current LR: 5e-05\n",
      "epoch: 28, train loss: 1.26281,  train_accuracy: 0.61490, test_accuracy 0.61901\n",
      "current LR: 5e-05\n",
      "epoch: 29, train loss: 1.20840,  train_accuracy: 0.61430, test_accuracy 0.61851\n",
      "current LR: 5e-05\n",
      "epoch: 30, train loss: 1.25494,  train_accuracy: 0.61557, test_accuracy 0.61928\n",
      "current LR: 5e-05\n",
      "epoch: 31, train loss: 1.22463,  train_accuracy: 0.61533, test_accuracy 0.61924\n",
      "current LR: 5e-05\n",
      "epoch: 32, train loss: 1.21855,  train_accuracy: 0.61553, test_accuracy 0.61797\n",
      "current LR: 5e-05\n",
      "epoch: 33, train loss: 1.22679,  train_accuracy: 0.61484, test_accuracy 0.61689\n",
      "current LR: 5e-05\n",
      "epoch: 34, train loss: 1.21776,  train_accuracy: 0.61593, test_accuracy 0.61858\n",
      "current LR: 5e-05\n",
      "epoch: 35, train loss: 1.25992,  train_accuracy: 0.61696, test_accuracy 0.61835\n",
      "current LR: 5e-05\n",
      "epoch: 36, train loss: 1.14133,  train_accuracy: 0.61661, test_accuracy 0.61955\n",
      "current LR: 5e-05\n",
      "epoch: 37, train loss: 1.17330,  train_accuracy: 0.61630, test_accuracy 0.61962\n",
      "current LR: 5e-05\n",
      "epoch: 38, train loss: 1.22588,  train_accuracy: 0.61679, test_accuracy 0.61874\n",
      "current LR: 5e-05\n",
      "epoch: 39, train loss: 1.18190,  train_accuracy: 0.61744, test_accuracy 0.62043\n",
      "current LR: 1.25e-05\n",
      "epoch: 40, train loss: 1.18460,  train_accuracy: 0.61773, test_accuracy 0.62066\n",
      "current LR: 2.5e-05\n",
      "epoch: 41, train loss: 1.20882,  train_accuracy: 0.61855, test_accuracy 0.61970\n",
      "current LR: 2.5e-05\n",
      "epoch: 42, train loss: 1.24142,  train_accuracy: 0.61838, test_accuracy 0.61928\n",
      "current LR: 2.5e-05\n",
      "epoch: 43, train loss: 1.15228,  train_accuracy: 0.61899, test_accuracy 0.62054\n",
      "current LR: 2.5e-05\n",
      "epoch: 44, train loss: 1.18321,  train_accuracy: 0.61907, test_accuracy 0.62039\n",
      "current LR: 2.5e-05\n",
      "epoch: 45, train loss: 1.16429,  train_accuracy: 0.61924, test_accuracy 0.62051\n",
      "current LR: 2.5e-05\n",
      "epoch: 46, train loss: 1.20769,  train_accuracy: 0.61821, test_accuracy 0.61920\n",
      "current LR: 2.5e-05\n",
      "epoch: 47, train loss: 1.21538,  train_accuracy: 0.61802, test_accuracy 0.62074\n",
      "current LR: 2.5e-05\n",
      "epoch: 48, train loss: 1.18253,  train_accuracy: 0.61822, test_accuracy 0.62089\n",
      "current LR: 2.5e-05\n",
      "epoch: 49, train loss: 1.20996,  train_accuracy: 0.61871, test_accuracy 0.62116\n",
      "current LR: 2.5e-05\n",
      "epoch: 50, train loss: 1.17179,  train_accuracy: 0.61919, test_accuracy 0.62020\n",
      "current LR: 2.5e-05\n",
      "epoch: 51, train loss: 1.21918,  train_accuracy: 0.61840, test_accuracy 0.62031\n",
      "current LR: 2.5e-05\n",
      "epoch: 52, train loss: 1.23977,  train_accuracy: 0.61843, test_accuracy 0.61920\n",
      "current LR: 2.5e-05\n",
      "epoch: 53, train loss: 1.12386,  train_accuracy: 0.61948, test_accuracy 0.62100\n",
      "current LR: 2.5e-05\n",
      "epoch: 54, train loss: 1.18423,  train_accuracy: 0.61949, test_accuracy 0.62097\n",
      "current LR: 2.5e-05\n",
      "epoch: 55, train loss: 1.20184,  train_accuracy: 0.61884, test_accuracy 0.61931\n",
      "current LR: 2.5e-05\n",
      "epoch: 56, train loss: 1.24278,  train_accuracy: 0.61848, test_accuracy 0.62100\n",
      "current LR: 2.5e-05\n",
      "epoch: 57, train loss: 1.24771,  train_accuracy: 0.61907, test_accuracy 0.62100\n",
      "current LR: 2.5e-05\n",
      "epoch: 58, train loss: 1.17456,  train_accuracy: 0.61935, test_accuracy 0.62004\n",
      "current LR: 2.5e-05\n",
      "epoch: 59, train loss: 1.18236,  train_accuracy: 0.61882, test_accuracy 0.62135\n",
      "current LR: 6.25e-06\n",
      "epoch: 60, train loss: 1.21564,  train_accuracy: 0.61937, test_accuracy 0.62066\n",
      "current LR: 1.25e-05\n",
      "epoch: 61, train loss: 1.21655,  train_accuracy: 0.62083, test_accuracy 0.62166\n",
      "current LR: 1.25e-05\n",
      "epoch: 62, train loss: 1.20907,  train_accuracy: 0.61961, test_accuracy 0.62093\n",
      "current LR: 1.25e-05\n",
      "epoch: 63, train loss: 1.17789,  train_accuracy: 0.62020, test_accuracy 0.62112\n",
      "current LR: 1.25e-05\n",
      "epoch: 64, train loss: 1.18886,  train_accuracy: 0.62054, test_accuracy 0.62062\n",
      "current LR: 1.25e-05\n",
      "epoch: 65, train loss: 1.19324,  train_accuracy: 0.61991, test_accuracy 0.61997\n",
      "current LR: 1.25e-05\n",
      "epoch: 66, train loss: 1.19872,  train_accuracy: 0.62027, test_accuracy 0.61978\n",
      "current LR: 1.25e-05\n",
      "epoch: 67, train loss: 1.21895,  train_accuracy: 0.61979, test_accuracy 0.62077\n",
      "current LR: 1.25e-05\n",
      "epoch: 68, train loss: 1.18486,  train_accuracy: 0.61912, test_accuracy 0.62097\n",
      "current LR: 1.25e-05\n",
      "epoch: 69, train loss: 1.17356,  train_accuracy: 0.62075, test_accuracy 0.62077\n",
      "current LR: 1.25e-05\n",
      "epoch: 70, train loss: 1.16704,  train_accuracy: 0.62057, test_accuracy 0.62120\n",
      "current LR: 1.25e-05\n",
      "epoch: 71, train loss: 1.19364,  train_accuracy: 0.62040, test_accuracy 0.61981\n",
      "current LR: 1.25e-05\n",
      "epoch: 72, train loss: 1.16351,  train_accuracy: 0.62001, test_accuracy 0.62020\n",
      "current LR: 1.25e-05\n",
      "epoch: 73, train loss: 1.12609,  train_accuracy: 0.61982, test_accuracy 0.62124\n",
      "current LR: 1.25e-05\n",
      "epoch: 74, train loss: 1.20137,  train_accuracy: 0.62016, test_accuracy 0.62097\n",
      "current LR: 1.25e-05\n",
      "epoch: 75, train loss: 1.21795,  train_accuracy: 0.61994, test_accuracy 0.62089\n",
      "current LR: 1.25e-05\n",
      "epoch: 76, train loss: 1.15457,  train_accuracy: 0.62109, test_accuracy 0.62104\n",
      "current LR: 1.25e-05\n",
      "epoch: 77, train loss: 1.23997,  train_accuracy: 0.62192, test_accuracy 0.62077\n",
      "current LR: 1.25e-05\n",
      "epoch: 78, train loss: 1.09544,  train_accuracy: 0.62058, test_accuracy 0.62185\n",
      "current LR: 1.25e-05\n",
      "epoch: 79, train loss: 1.27228,  train_accuracy: 0.62020, test_accuracy 0.62047\n",
      "current LR: 3.125e-06\n",
      "epoch: 80, train loss: 1.22824,  train_accuracy: 0.62047, test_accuracy 0.62100\n",
      "current LR: 6.25e-06\n",
      "epoch: 81, train loss: 1.19045,  train_accuracy: 0.62129, test_accuracy 0.62051\n",
      "current LR: 6.25e-06\n",
      "epoch: 82, train loss: 1.20877,  train_accuracy: 0.62139, test_accuracy 0.62139\n",
      "current LR: 6.25e-06\n",
      "epoch: 83, train loss: 1.17459,  train_accuracy: 0.62020, test_accuracy 0.62104\n",
      "current LR: 6.25e-06\n",
      "epoch: 84, train loss: 1.16077,  train_accuracy: 0.62105, test_accuracy 0.62081\n",
      "current LR: 6.25e-06\n",
      "epoch: 85, train loss: 1.19212,  train_accuracy: 0.62024, test_accuracy 0.62031\n",
      "current LR: 6.25e-06\n",
      "epoch: 86, train loss: 1.14070,  train_accuracy: 0.62169, test_accuracy 0.62081\n",
      "current LR: 6.25e-06\n",
      "epoch: 87, train loss: 1.14526,  train_accuracy: 0.62166, test_accuracy 0.62097\n",
      "current LR: 6.25e-06\n",
      "epoch: 88, train loss: 1.16775,  train_accuracy: 0.62045, test_accuracy 0.62066\n",
      "current LR: 6.25e-06\n",
      "epoch: 89, train loss: 1.17595,  train_accuracy: 0.61950, test_accuracy 0.62054\n",
      "current LR: 6.25e-06\n",
      "epoch: 90, train loss: 1.17419,  train_accuracy: 0.62061, test_accuracy 0.62066\n",
      "current LR: 6.25e-06\n",
      "epoch: 91, train loss: 1.17741,  train_accuracy: 0.62114, test_accuracy 0.62089\n",
      "current LR: 6.25e-06\n",
      "epoch: 92, train loss: 1.15545,  train_accuracy: 0.62147, test_accuracy 0.62100\n",
      "current LR: 6.25e-06\n",
      "epoch: 93, train loss: 1.21394,  train_accuracy: 0.62075, test_accuracy 0.62093\n",
      "current LR: 6.25e-06\n",
      "epoch: 94, train loss: 1.20338,  train_accuracy: 0.62142, test_accuracy 0.62028\n",
      "current LR: 6.25e-06\n",
      "epoch: 95, train loss: 1.10176,  train_accuracy: 0.62038, test_accuracy 0.62062\n",
      "current LR: 6.25e-06\n",
      "epoch: 96, train loss: 1.11833,  train_accuracy: 0.62143, test_accuracy 0.62066\n",
      "current LR: 6.25e-06\n",
      "epoch: 97, train loss: 1.11204,  train_accuracy: 0.62161, test_accuracy 0.62077\n",
      "current LR: 6.25e-06\n",
      "epoch: 98, train loss: 1.21795,  train_accuracy: 0.62051, test_accuracy 0.62028\n",
      "current LR: 6.25e-06\n",
      "epoch: 99, train loss: 1.13933,  train_accuracy: 0.62125, test_accuracy 0.62016\n",
      "current LR: 1.5625e-06\n",
      "epoch: 100, train loss: 1.23804,  train_accuracy: 0.62064, test_accuracy 0.62047\n",
      "current LR: 3.125e-06\n",
      "epoch: 101, train loss: 1.11354,  train_accuracy: 0.62083, test_accuracy 0.62024\n",
      "current LR: 3.125e-06\n",
      "epoch: 102, train loss: 1.18937,  train_accuracy: 0.62102, test_accuracy 0.62085\n",
      "current LR: 3.125e-06\n",
      "epoch: 103, train loss: 1.13024,  train_accuracy: 0.62049, test_accuracy 0.62081\n",
      "current LR: 3.125e-06\n",
      "epoch: 104, train loss: 1.18594,  train_accuracy: 0.62056, test_accuracy 0.62031\n",
      "current LR: 3.125e-06\n",
      "epoch: 105, train loss: 1.12807,  train_accuracy: 0.62008, test_accuracy 0.62001\n",
      "current LR: 3.125e-06\n",
      "epoch: 106, train loss: 1.19810,  train_accuracy: 0.62178, test_accuracy 0.62054\n",
      "current LR: 3.125e-06\n",
      "epoch: 107, train loss: 1.14946,  train_accuracy: 0.62181, test_accuracy 0.62031\n",
      "current LR: 3.125e-06\n",
      "epoch: 108, train loss: 1.18326,  train_accuracy: 0.62049, test_accuracy 0.62051\n",
      "current LR: 3.125e-06\n",
      "epoch: 109, train loss: 1.20210,  train_accuracy: 0.62035, test_accuracy 0.62051\n",
      "current LR: 3.125e-06\n",
      "epoch: 110, train loss: 1.17211,  train_accuracy: 0.62042, test_accuracy 0.62051\n",
      "current LR: 3.125e-06\n",
      "epoch: 111, train loss: 1.10665,  train_accuracy: 0.62071, test_accuracy 0.62054\n",
      "current LR: 3.125e-06\n",
      "epoch: 112, train loss: 1.15764,  train_accuracy: 0.62016, test_accuracy 0.62066\n",
      "current LR: 3.125e-06\n",
      "epoch: 113, train loss: 1.16092,  train_accuracy: 0.62006, test_accuracy 0.62020\n",
      "current LR: 3.125e-06\n",
      "epoch: 114, train loss: 1.28447,  train_accuracy: 0.62170, test_accuracy 0.62047\n",
      "current LR: 3.125e-06\n",
      "epoch: 115, train loss: 1.18970,  train_accuracy: 0.62113, test_accuracy 0.62062\n",
      "current LR: 3.125e-06\n",
      "epoch: 116, train loss: 1.21258,  train_accuracy: 0.61989, test_accuracy 0.62070\n",
      "current LR: 3.125e-06\n",
      "epoch: 117, train loss: 1.21678,  train_accuracy: 0.61972, test_accuracy 0.62062\n",
      "current LR: 3.125e-06\n",
      "epoch: 118, train loss: 1.18545,  train_accuracy: 0.62043, test_accuracy 0.62089\n",
      "current LR: 3.125e-06\n",
      "epoch: 119, train loss: 1.17790,  train_accuracy: 0.62096, test_accuracy 0.62066\n",
      "current LR: 7.8125e-07\n",
      "epoch: 120, train loss: 1.17681,  train_accuracy: 0.62098, test_accuracy 0.62077\n",
      "current LR: 1.5625e-06\n",
      "epoch: 121, train loss: 1.16501,  train_accuracy: 0.62135, test_accuracy 0.62074\n",
      "current LR: 1.5625e-06\n",
      "epoch: 122, train loss: 1.16389,  train_accuracy: 0.62075, test_accuracy 0.62085\n",
      "current LR: 1.5625e-06\n",
      "epoch: 123, train loss: 1.19440,  train_accuracy: 0.62113, test_accuracy 0.62066\n",
      "current LR: 1.5625e-06\n",
      "epoch: 124, train loss: 1.08681,  train_accuracy: 0.62080, test_accuracy 0.62043\n",
      "current LR: 1.5625e-06\n",
      "epoch: 125, train loss: 1.17506,  train_accuracy: 0.62083, test_accuracy 0.62058\n",
      "current LR: 1.5625e-06\n",
      "epoch: 126, train loss: 1.10611,  train_accuracy: 0.62197, test_accuracy 0.62070\n",
      "current LR: 1.5625e-06\n",
      "epoch: 127, train loss: 1.16325,  train_accuracy: 0.62094, test_accuracy 0.62070\n",
      "current LR: 1.5625e-06\n",
      "epoch: 128, train loss: 1.29757,  train_accuracy: 0.62177, test_accuracy 0.62074\n",
      "current LR: 1.5625e-06\n",
      "epoch: 129, train loss: 1.19166,  train_accuracy: 0.62045, test_accuracy 0.62051\n",
      "current LR: 1.5625e-06\n",
      "epoch: 130, train loss: 1.14759,  train_accuracy: 0.62106, test_accuracy 0.62051\n",
      "current LR: 1.5625e-06\n",
      "epoch: 131, train loss: 1.16556,  train_accuracy: 0.62090, test_accuracy 0.62051\n",
      "current LR: 1.5625e-06\n",
      "epoch: 132, train loss: 1.15061,  train_accuracy: 0.62034, test_accuracy 0.62058\n",
      "current LR: 1.5625e-06\n",
      "epoch: 133, train loss: 1.24421,  train_accuracy: 0.62163, test_accuracy 0.62062\n",
      "current LR: 1.5625e-06\n",
      "epoch: 134, train loss: 1.18972,  train_accuracy: 0.62177, test_accuracy 0.62051\n",
      "current LR: 1.5625e-06\n",
      "epoch: 135, train loss: 1.23756,  train_accuracy: 0.62072, test_accuracy 0.62077\n",
      "current LR: 1.5625e-06\n",
      "epoch: 136, train loss: 1.23915,  train_accuracy: 0.62133, test_accuracy 0.62070\n",
      "current LR: 1.5625e-06\n",
      "epoch: 137, train loss: 1.14677,  train_accuracy: 0.62077, test_accuracy 0.62066\n",
      "current LR: 1.5625e-06\n",
      "epoch: 138, train loss: 1.17138,  train_accuracy: 0.62124, test_accuracy 0.62081\n",
      "current LR: 1.5625e-06\n",
      "epoch: 139, train loss: 1.18091,  train_accuracy: 0.62142, test_accuracy 0.62081\n",
      "current LR: 3.90625e-07\n",
      "epoch: 140, train loss: 1.13834,  train_accuracy: 0.62060, test_accuracy 0.62058\n",
      "current LR: 7.8125e-07\n",
      "epoch: 141, train loss: 1.08004,  train_accuracy: 0.62180, test_accuracy 0.62054\n",
      "current LR: 7.8125e-07\n",
      "epoch: 142, train loss: 1.20099,  train_accuracy: 0.62096, test_accuracy 0.62074\n",
      "current LR: 7.8125e-07\n",
      "epoch: 143, train loss: 1.13422,  train_accuracy: 0.62206, test_accuracy 0.62077\n",
      "current LR: 7.8125e-07\n",
      "epoch: 144, train loss: 1.21728,  train_accuracy: 0.62126, test_accuracy 0.62074\n",
      "current LR: 7.8125e-07\n",
      "epoch: 145, train loss: 1.19812,  train_accuracy: 0.62162, test_accuracy 0.62077\n",
      "current LR: 7.8125e-07\n",
      "epoch: 146, train loss: 1.16841,  train_accuracy: 0.62158, test_accuracy 0.62081\n",
      "current LR: 7.8125e-07\n",
      "epoch: 147, train loss: 1.12444,  train_accuracy: 0.62091, test_accuracy 0.62093\n",
      "current LR: 7.8125e-07\n",
      "epoch: 148, train loss: 1.19584,  train_accuracy: 0.62002, test_accuracy 0.62070\n",
      "current LR: 7.8125e-07\n",
      "epoch: 149, train loss: 1.27046,  train_accuracy: 0.62066, test_accuracy 0.62093\n",
      "current LR: 7.8125e-07\n",
      "epoch: 150, train loss: 1.17879,  train_accuracy: 0.62148, test_accuracy 0.62074\n",
      "current LR: 7.8125e-07\n",
      "epoch: 151, train loss: 1.14913,  train_accuracy: 0.62124, test_accuracy 0.62100\n",
      "current LR: 7.8125e-07\n",
      "epoch: 152, train loss: 1.12910,  train_accuracy: 0.62116, test_accuracy 0.62112\n",
      "current LR: 7.8125e-07\n",
      "epoch: 153, train loss: 1.15066,  train_accuracy: 0.62165, test_accuracy 0.62100\n",
      "current LR: 7.8125e-07\n",
      "epoch: 154, train loss: 1.18869,  train_accuracy: 0.62161, test_accuracy 0.62116\n",
      "current LR: 7.8125e-07\n",
      "epoch: 155, train loss: 1.22643,  train_accuracy: 0.62001, test_accuracy 0.62108\n",
      "current LR: 7.8125e-07\n",
      "epoch: 156, train loss: 1.11714,  train_accuracy: 0.62193, test_accuracy 0.62089\n",
      "current LR: 7.8125e-07\n",
      "epoch: 157, train loss: 1.19162,  train_accuracy: 0.62105, test_accuracy 0.62081\n",
      "current LR: 7.8125e-07\n",
      "epoch: 158, train loss: 1.19730,  train_accuracy: 0.62024, test_accuracy 0.62093\n",
      "current LR: 7.8125e-07\n",
      "epoch: 159, train loss: 1.24650,  train_accuracy: 0.62155, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 160, train loss: 1.17062,  train_accuracy: 0.62058, test_accuracy 0.62089\n",
      "current LR: 3.90625e-07\n",
      "epoch: 161, train loss: 1.21686,  train_accuracy: 0.62133, test_accuracy 0.62093\n",
      "current LR: 3.90625e-07\n",
      "epoch: 162, train loss: 1.16809,  train_accuracy: 0.62154, test_accuracy 0.62089\n",
      "current LR: 3.90625e-07\n",
      "epoch: 163, train loss: 1.19044,  train_accuracy: 0.62189, test_accuracy 0.62085\n",
      "current LR: 3.90625e-07\n",
      "epoch: 164, train loss: 1.20321,  train_accuracy: 0.62116, test_accuracy 0.62074\n",
      "current LR: 3.90625e-07\n",
      "epoch: 165, train loss: 1.21757,  train_accuracy: 0.62152, test_accuracy 0.62074\n",
      "current LR: 3.90625e-07\n",
      "epoch: 166, train loss: 1.20562,  train_accuracy: 0.62071, test_accuracy 0.62085\n",
      "current LR: 3.90625e-07\n",
      "epoch: 167, train loss: 1.12987,  train_accuracy: 0.62169, test_accuracy 0.62093\n",
      "current LR: 3.90625e-07\n",
      "epoch: 168, train loss: 1.18546,  train_accuracy: 0.62069, test_accuracy 0.62085\n",
      "current LR: 3.90625e-07\n",
      "epoch: 169, train loss: 1.10663,  train_accuracy: 0.62146, test_accuracy 0.62085\n",
      "current LR: 3.90625e-07\n",
      "epoch: 170, train loss: 1.22266,  train_accuracy: 0.62206, test_accuracy 0.62077\n",
      "current LR: 3.90625e-07\n",
      "epoch: 171, train loss: 1.15514,  train_accuracy: 0.62047, test_accuracy 0.62077\n",
      "current LR: 3.90625e-07\n",
      "epoch: 172, train loss: 1.18458,  train_accuracy: 0.62173, test_accuracy 0.62077\n",
      "current LR: 3.90625e-07\n",
      "epoch: 173, train loss: 1.14431,  train_accuracy: 0.62069, test_accuracy 0.62074\n",
      "current LR: 3.90625e-07\n",
      "epoch: 174, train loss: 1.21416,  train_accuracy: 0.62083, test_accuracy 0.62077\n",
      "current LR: 3.90625e-07\n",
      "epoch: 175, train loss: 1.19253,  train_accuracy: 0.62181, test_accuracy 0.62077\n",
      "current LR: 3.90625e-07\n",
      "epoch: 176, train loss: 1.17947,  train_accuracy: 0.62244, test_accuracy 0.62085\n",
      "current LR: 3.90625e-07\n",
      "epoch: 177, train loss: 1.16052,  train_accuracy: 0.62200, test_accuracy 0.62077\n",
      "current LR: 3.90625e-07\n",
      "epoch: 178, train loss: 1.20656,  train_accuracy: 0.62099, test_accuracy 0.62100\n",
      "current LR: 3.90625e-07\n",
      "epoch: 179, train loss: 1.15264,  train_accuracy: 0.62137, test_accuracy 0.62104\n",
      "current LR: 9.765625e-08\n",
      "epoch: 180, train loss: 1.15841,  train_accuracy: 0.62120, test_accuracy 0.62077\n",
      "current LR: 1.953125e-07\n",
      "epoch: 181, train loss: 1.12080,  train_accuracy: 0.62189, test_accuracy 0.62089\n",
      "current LR: 1.953125e-07\n",
      "epoch: 182, train loss: 1.19175,  train_accuracy: 0.62051, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 183, train loss: 1.25157,  train_accuracy: 0.62050, test_accuracy 0.62077\n",
      "current LR: 1.953125e-07\n",
      "epoch: 184, train loss: 1.19726,  train_accuracy: 0.62118, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 185, train loss: 1.18398,  train_accuracy: 0.62118, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 186, train loss: 1.17338,  train_accuracy: 0.62094, test_accuracy 0.62077\n",
      "current LR: 1.953125e-07\n",
      "epoch: 187, train loss: 1.15491,  train_accuracy: 0.62099, test_accuracy 0.62081\n",
      "current LR: 1.953125e-07\n",
      "epoch: 188, train loss: 1.16409,  train_accuracy: 0.62129, test_accuracy 0.62085\n",
      "current LR: 1.953125e-07\n",
      "epoch: 189, train loss: 1.13844,  train_accuracy: 0.62188, test_accuracy 0.62085\n",
      "current LR: 1.953125e-07\n",
      "epoch: 190, train loss: 1.17946,  train_accuracy: 0.62004, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 191, train loss: 1.19843,  train_accuracy: 0.62079, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 192, train loss: 1.21297,  train_accuracy: 0.62084, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 193, train loss: 1.14131,  train_accuracy: 0.62008, test_accuracy 0.62104\n",
      "current LR: 1.953125e-07\n",
      "epoch: 194, train loss: 1.27131,  train_accuracy: 0.62069, test_accuracy 0.62100\n",
      "current LR: 1.953125e-07\n",
      "epoch: 195, train loss: 1.17076,  train_accuracy: 0.62051, test_accuracy 0.62100\n",
      "current LR: 1.953125e-07\n",
      "epoch: 196, train loss: 1.21356,  train_accuracy: 0.62117, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 197, train loss: 1.11029,  train_accuracy: 0.62106, test_accuracy 0.62100\n",
      "current LR: 1.953125e-07\n",
      "epoch: 198, train loss: 1.24917,  train_accuracy: 0.61995, test_accuracy 0.62093\n",
      "current LR: 1.953125e-07\n",
      "epoch: 199, train loss: 1.17491,  train_accuracy: 0.62079, test_accuracy 0.62093\n",
      "current LR: 4.8828125e-08\n"
     ]
    }
   ],
   "source": [
    "#linear_model = train_linear_model(model_name=model_name, device=device, emb_size=768)\n",
    "in_dist_data = 'svhn'\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=768, in_dist_data=in_dist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_{in_dist_data}_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vit_base_patch16_384 with 1000 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'vit_base_patch16_384'\n",
    "model = timm.create_model(model_name, pretrained=True, ).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "imagenet_sanity_check(model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "svhn_data_train = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform\n",
    ")\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax ImageNet resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_model = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "soft_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/workspaces/ood/data/models/torch/hub/checkpoints/resnet50-0676ba61.pth\"\n",
    "    )\n",
    ")\n",
    "summary(soft_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import imagenet_sanity_check\n",
    "\n",
    "imagenet_sanity_check(soft_model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(soft_model, cifar_data_train, \"soft_cifar_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"soft\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/soft_cifar_linear_model0.88test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCo v2 ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_moco\n",
    "\n",
    "model = load_moco(\"/workspaces/ood/data/models/moco_v2_800ep_pretrain.pth.tar\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import add_labels, predict_on_whole_dataset_moco\n",
    "\n",
    "predict_on_whole_dataset_moco(model, cifar_data_test, \"moco_cifar_test\", device)\n",
    "predict_on_whole_dataset_moco(model, cifar_data_train, \"moco_cifar_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_train, \"moco_svhn_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_test, \"moco_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"moco\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/moco_cifar_linear_model0.8382test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_byol\n",
    "\n",
    "model = load_byol(\"/workspaces/ood/data/models/pretrain_res50x1.pth.tar\", device)\n",
    "\n",
    "model_name = \"byol\"\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"byol\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model0.905test_accuracy.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
