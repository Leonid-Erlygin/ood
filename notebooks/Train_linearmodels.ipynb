{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from scripts_ood.train import train_linear_model\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5),\n",
    "])\n",
    "\n",
    "\n",
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "svhn_data_train = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform\n",
    ")\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loaded pretrained weights.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "\n",
    "from scripts_ood.utils import load_pretrained_weights_vit\n",
    "# Load ViT\n",
    "from pytorch_pretrained_vit import ViT\n",
    "model = ViT('B_16_imagenet1k', pretrained=False).to(device)\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "weights_path='/workspaces/ood/data/models/B_16_imagenet1k.pth'\n",
    "load_pretrained_weights_vit(model, weights_path=weights_path)\n",
    "model.eval();\n",
    "# Load image\n",
    "# NOTE: Assumes an image `img.jpg` exists in the current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"281: 'tabby, tabby cat',model_pre\", \"282: 'tiger cat'\", \"285: 'Egyptian cat'\", \"287: 'lynx, catamount'\", \"292: 'tiger, Panthera tigris'\", \"283: 'Persian cat'\", \"284: 'Siamese cat, Siamese'\", \"622: 'lens cap, lens cover'\", \"248: 'Eskimo dog, husky'\", \"289: 'snow leopard, ounce, Panthera uncia'\"]\n"
     ]
    }
   ],
   "source": [
    "from scripts_ood.utils import imagenet_sanity_check\n",
    "\n",
    "imagenet_sanity_check(model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/10000 [00:00<04:31, 36.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1000]) torch.Size([20, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/50000 [00:00<20:28, 40.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1000]) torch.Size([20, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predict_on_whole_dataset_moco' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5215871089e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict_on_whole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcifar_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_name}_cifar_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredict_on_whole_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcifar_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_name}_cifar_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredict_on_whole_dataset_moco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_name}_svhn_train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpredict_on_whole_dataset_moco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvhn_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_name}_svhn_test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_on_whole_dataset_moco' is not defined"
     ]
    }
   ],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "model_name = 'B_16_imagenet1k'\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax ImageNet resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_model = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "soft_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/workspaces/ood/data/models/torch/hub/checkpoints/resnet50-0676ba61.pth\"\n",
    "    )\n",
    ")\n",
    "summary(soft_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import imagenet_sanity_check\n",
    "\n",
    "imagenet_sanity_check(soft_model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(soft_model, cifar_data_train, \"soft_cifar_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"soft\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/soft_cifar_linear_model0.88test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCo v2 ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_moco\n",
    "\n",
    "model = load_moco(\"/workspaces/ood/data/models/moco_v2_800ep_pretrain.pth.tar\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import add_labels, predict_on_whole_dataset_moco\n",
    "\n",
    "predict_on_whole_dataset_moco(model, cifar_data_test, \"moco_cifar_test\", device)\n",
    "predict_on_whole_dataset_moco(model, cifar_data_train, \"moco_cifar_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_train, \"moco_svhn_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_test, \"moco_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"moco\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/moco_cifar_linear_model0.8382test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_byol\n",
    "\n",
    "model = load_byol(\"/workspaces/ood/data/models/pretrain_res50x1.pth.tar\", device)\n",
    "\n",
    "model_name = \"byol\"\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"byol\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model0.905test_accuracy.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
