{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from scripts_ood.train import train_linear_model\n",
    "import warnings\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from pytorch_pretrained_vit import ViT\n",
    "from scripts_ood.utils import imagenet_sanity_check\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import timm\n",
    "\n",
    "from scripts_ood.utils import load_pretrained_weights_vit\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 2.71435,  train_accuracy: 0.11009, test_accuracy 0.10622\n",
      "current LR: 0.0001\n",
      "epoch: 1, train loss: 1.41096,  train_accuracy: 0.59259, test_accuracy 0.59888\n",
      "current LR: 0.0001\n",
      "epoch: 2, train loss: 1.23532,  train_accuracy: 0.67356, test_accuracy 0.67555\n",
      "current LR: 0.0001\n",
      "epoch: 3, train loss: 1.12989,  train_accuracy: 0.70988, test_accuracy 0.71397\n",
      "current LR: 0.0001\n",
      "epoch: 4, train loss: 1.11953,  train_accuracy: 0.73380, test_accuracy 0.73187\n",
      "current LR: 0.0001\n",
      "epoch: 5, train loss: 1.06228,  train_accuracy: 0.74838, test_accuracy 0.74416\n",
      "current LR: 0.0001\n",
      "epoch: 6, train loss: 1.00625,  train_accuracy: 0.75706, test_accuracy 0.75319\n",
      "current LR: 0.0001\n",
      "epoch: 7, train loss: 0.98584,  train_accuracy: 0.76431, test_accuracy 0.75515\n",
      "current LR: 0.0001\n",
      "epoch: 8, train loss: 0.96165,  train_accuracy: 0.77161, test_accuracy 0.75968\n",
      "current LR: 0.0001\n",
      "epoch: 9, train loss: 0.94267,  train_accuracy: 0.77479, test_accuracy 0.76245\n",
      "current LR: 0.0001\n",
      "epoch: 10, train loss: 0.93116,  train_accuracy: 0.77860, test_accuracy 0.76563\n",
      "current LR: 0.0001\n",
      "epoch: 11, train loss: 0.95484,  train_accuracy: 0.78285, test_accuracy 0.76721\n",
      "current LR: 0.0001\n",
      "epoch: 12, train loss: 0.85595,  train_accuracy: 0.78408, test_accuracy 0.76855\n",
      "current LR: 0.0001\n",
      "epoch: 13, train loss: 0.91805,  train_accuracy: 0.78633, test_accuracy 0.76805\n",
      "current LR: 0.0001\n",
      "epoch: 14, train loss: 0.87919,  train_accuracy: 0.78888, test_accuracy 0.76936\n",
      "current LR: 0.0001\n",
      "epoch: 15, train loss: 0.87793,  train_accuracy: 0.79090, test_accuracy 0.77086\n",
      "current LR: 0.0001\n",
      "epoch: 16, train loss: 0.87594,  train_accuracy: 0.78979, test_accuracy 0.76859\n",
      "current LR: 0.0001\n",
      "epoch: 17, train loss: 0.88047,  train_accuracy: 0.79326, test_accuracy 0.76925\n",
      "current LR: 0.0001\n",
      "epoch: 18, train loss: 0.81911,  train_accuracy: 0.79292, test_accuracy 0.77024\n",
      "current LR: 0.0001\n",
      "epoch: 19, train loss: 0.83911,  train_accuracy: 0.79461, test_accuracy 0.77047\n",
      "current LR: 2.5e-05\n",
      "epoch: 20, train loss: 0.77829,  train_accuracy: 0.79583, test_accuracy 0.77151\n",
      "current LR: 5e-05\n",
      "epoch: 21, train loss: 0.80680,  train_accuracy: 0.79603, test_accuracy 0.77182\n",
      "current LR: 5e-05\n",
      "epoch: 22, train loss: 0.84437,  train_accuracy: 0.79778, test_accuracy 0.77201\n",
      "current LR: 5e-05\n",
      "epoch: 23, train loss: 0.84787,  train_accuracy: 0.79826, test_accuracy 0.77278\n",
      "current LR: 5e-05\n",
      "epoch: 24, train loss: 0.82031,  train_accuracy: 0.79725, test_accuracy 0.77174\n",
      "current LR: 5e-05\n",
      "epoch: 25, train loss: 0.76839,  train_accuracy: 0.79723, test_accuracy 0.77255\n",
      "current LR: 5e-05\n",
      "epoch: 26, train loss: 0.81336,  train_accuracy: 0.79915, test_accuracy 0.77174\n",
      "current LR: 5e-05\n",
      "epoch: 27, train loss: 0.80275,  train_accuracy: 0.79979, test_accuracy 0.77159\n",
      "current LR: 5e-05\n",
      "epoch: 28, train loss: 0.80253,  train_accuracy: 0.79912, test_accuracy 0.77105\n",
      "current LR: 5e-05\n",
      "epoch: 29, train loss: 0.79596,  train_accuracy: 0.79954, test_accuracy 0.77190\n",
      "current LR: 5e-05\n",
      "epoch: 30, train loss: 0.81035,  train_accuracy: 0.80100, test_accuracy 0.77401\n",
      "current LR: 5e-05\n",
      "epoch: 31, train loss: 0.75584,  train_accuracy: 0.80074, test_accuracy 0.77197\n",
      "current LR: 5e-05\n",
      "epoch: 32, train loss: 0.78946,  train_accuracy: 0.80001, test_accuracy 0.77170\n",
      "current LR: 5e-05\n",
      "epoch: 33, train loss: 0.83069,  train_accuracy: 0.80110, test_accuracy 0.77193\n",
      "current LR: 5e-05\n",
      "epoch: 34, train loss: 0.79879,  train_accuracy: 0.80209, test_accuracy 0.77240\n",
      "current LR: 5e-05\n",
      "epoch: 35, train loss: 0.79605,  train_accuracy: 0.80084, test_accuracy 0.77232\n",
      "current LR: 5e-05\n",
      "epoch: 36, train loss: 0.81654,  train_accuracy: 0.80237, test_accuracy 0.77324\n",
      "current LR: 5e-05\n",
      "epoch: 37, train loss: 0.78501,  train_accuracy: 0.80234, test_accuracy 0.77217\n",
      "current LR: 5e-05\n",
      "epoch: 38, train loss: 0.78076,  train_accuracy: 0.80197, test_accuracy 0.77305\n",
      "current LR: 5e-05\n",
      "epoch: 39, train loss: 0.74185,  train_accuracy: 0.80280, test_accuracy 0.77251\n",
      "current LR: 1.25e-05\n",
      "epoch: 40, train loss: 0.76760,  train_accuracy: 0.80287, test_accuracy 0.77297\n",
      "current LR: 2.5e-05\n",
      "epoch: 41, train loss: 0.76511,  train_accuracy: 0.80308, test_accuracy 0.77320\n",
      "current LR: 2.5e-05\n",
      "epoch: 42, train loss: 0.74550,  train_accuracy: 0.80342, test_accuracy 0.77416\n",
      "current LR: 2.5e-05\n",
      "epoch: 43, train loss: 0.78444,  train_accuracy: 0.80321, test_accuracy 0.77243\n",
      "current LR: 2.5e-05\n",
      "epoch: 44, train loss: 0.74202,  train_accuracy: 0.80346, test_accuracy 0.77293\n",
      "current LR: 2.5e-05\n",
      "epoch: 45, train loss: 0.81562,  train_accuracy: 0.80342, test_accuracy 0.77255\n",
      "current LR: 2.5e-05\n",
      "epoch: 46, train loss: 0.69425,  train_accuracy: 0.80477, test_accuracy 0.77289\n",
      "current LR: 2.5e-05\n",
      "epoch: 47, train loss: 0.74959,  train_accuracy: 0.80511, test_accuracy 0.77232\n",
      "current LR: 2.5e-05\n",
      "epoch: 48, train loss: 0.78735,  train_accuracy: 0.80489, test_accuracy 0.77301\n",
      "current LR: 2.5e-05\n",
      "epoch: 49, train loss: 0.78911,  train_accuracy: 0.80474, test_accuracy 0.77324\n",
      "current LR: 2.5e-05\n",
      "epoch: 50, train loss: 0.73809,  train_accuracy: 0.80450, test_accuracy 0.77266\n",
      "current LR: 2.5e-05\n",
      "epoch: 51, train loss: 0.77362,  train_accuracy: 0.80433, test_accuracy 0.77320\n",
      "current LR: 2.5e-05\n",
      "epoch: 52, train loss: 0.78876,  train_accuracy: 0.80428, test_accuracy 0.77251\n",
      "current LR: 2.5e-05\n",
      "epoch: 53, train loss: 0.80977,  train_accuracy: 0.80466, test_accuracy 0.77328\n",
      "current LR: 2.5e-05\n",
      "epoch: 54, train loss: 0.73557,  train_accuracy: 0.80519, test_accuracy 0.77366\n",
      "current LR: 2.5e-05\n",
      "epoch: 55, train loss: 0.74577,  train_accuracy: 0.80470, test_accuracy 0.77297\n",
      "current LR: 2.5e-05\n",
      "epoch: 56, train loss: 0.76746,  train_accuracy: 0.80451, test_accuracy 0.77259\n",
      "current LR: 2.5e-05\n",
      "epoch: 57, train loss: 0.76616,  train_accuracy: 0.80355, test_accuracy 0.77266\n",
      "current LR: 2.5e-05\n",
      "epoch: 58, train loss: 0.70688,  train_accuracy: 0.80519, test_accuracy 0.77359\n",
      "current LR: 2.5e-05\n",
      "epoch: 59, train loss: 0.71572,  train_accuracy: 0.80536, test_accuracy 0.77347\n",
      "current LR: 6.25e-06\n",
      "epoch: 60, train loss: 0.70762,  train_accuracy: 0.80506, test_accuracy 0.77289\n",
      "current LR: 1.25e-05\n",
      "epoch: 61, train loss: 0.73346,  train_accuracy: 0.80433, test_accuracy 0.77324\n",
      "current LR: 1.25e-05\n",
      "epoch: 62, train loss: 0.74422,  train_accuracy: 0.80603, test_accuracy 0.77374\n",
      "current LR: 1.25e-05\n",
      "epoch: 63, train loss: 0.71607,  train_accuracy: 0.80544, test_accuracy 0.77324\n",
      "current LR: 1.25e-05\n",
      "epoch: 64, train loss: 0.76526,  train_accuracy: 0.80568, test_accuracy 0.77278\n",
      "current LR: 1.25e-05\n",
      "epoch: 65, train loss: 0.75347,  train_accuracy: 0.80557, test_accuracy 0.77328\n",
      "current LR: 1.25e-05\n",
      "epoch: 66, train loss: 0.76170,  train_accuracy: 0.80589, test_accuracy 0.77263\n",
      "current LR: 1.25e-05\n",
      "epoch: 67, train loss: 0.71552,  train_accuracy: 0.80597, test_accuracy 0.77251\n",
      "current LR: 1.25e-05\n",
      "epoch: 68, train loss: 0.74983,  train_accuracy: 0.80537, test_accuracy 0.77255\n",
      "current LR: 1.25e-05\n",
      "epoch: 69, train loss: 0.76849,  train_accuracy: 0.80567, test_accuracy 0.77270\n",
      "current LR: 1.25e-05\n",
      "epoch: 70, train loss: 0.76148,  train_accuracy: 0.80566, test_accuracy 0.77316\n",
      "current LR: 1.25e-05\n",
      "epoch: 71, train loss: 0.69977,  train_accuracy: 0.80538, test_accuracy 0.77339\n",
      "current LR: 1.25e-05\n",
      "epoch: 72, train loss: 0.76373,  train_accuracy: 0.80586, test_accuracy 0.77293\n",
      "current LR: 1.25e-05\n",
      "epoch: 73, train loss: 0.78730,  train_accuracy: 0.80615, test_accuracy 0.77297\n",
      "current LR: 1.25e-05\n",
      "epoch: 74, train loss: 0.73475,  train_accuracy: 0.80604, test_accuracy 0.77336\n",
      "current LR: 1.25e-05\n",
      "epoch: 75, train loss: 0.76073,  train_accuracy: 0.80661, test_accuracy 0.77339\n",
      "current LR: 1.25e-05\n",
      "epoch: 76, train loss: 0.72329,  train_accuracy: 0.80660, test_accuracy 0.77309\n",
      "current LR: 1.25e-05\n",
      "epoch: 77, train loss: 0.70358,  train_accuracy: 0.80657, test_accuracy 0.77286\n",
      "current LR: 1.25e-05\n",
      "epoch: 78, train loss: 0.73737,  train_accuracy: 0.80663, test_accuracy 0.77316\n",
      "current LR: 1.25e-05\n",
      "epoch: 79, train loss: 0.75234,  train_accuracy: 0.80628, test_accuracy 0.77347\n",
      "current LR: 3.125e-06\n",
      "epoch: 80, train loss: 0.72123,  train_accuracy: 0.80652, test_accuracy 0.77286\n",
      "current LR: 6.25e-06\n",
      "epoch: 81, train loss: 0.70263,  train_accuracy: 0.80674, test_accuracy 0.77282\n",
      "current LR: 6.25e-06\n",
      "epoch: 82, train loss: 0.72079,  train_accuracy: 0.80616, test_accuracy 0.77309\n",
      "current LR: 6.25e-06\n",
      "epoch: 83, train loss: 0.75717,  train_accuracy: 0.80634, test_accuracy 0.77343\n",
      "current LR: 6.25e-06\n",
      "epoch: 84, train loss: 0.70150,  train_accuracy: 0.80732, test_accuracy 0.77316\n",
      "current LR: 6.25e-06\n",
      "epoch: 85, train loss: 0.77004,  train_accuracy: 0.80661, test_accuracy 0.77301\n",
      "current LR: 6.25e-06\n",
      "epoch: 86, train loss: 0.71190,  train_accuracy: 0.80710, test_accuracy 0.77351\n",
      "current LR: 6.25e-06\n",
      "epoch: 87, train loss: 0.72987,  train_accuracy: 0.80657, test_accuracy 0.77328\n",
      "current LR: 6.25e-06\n",
      "epoch: 88, train loss: 0.73361,  train_accuracy: 0.80650, test_accuracy 0.77328\n",
      "current LR: 6.25e-06\n",
      "epoch: 89, train loss: 0.74595,  train_accuracy: 0.80710, test_accuracy 0.77305\n",
      "current LR: 6.25e-06\n",
      "epoch: 90, train loss: 0.73578,  train_accuracy: 0.80663, test_accuracy 0.77309\n",
      "current LR: 6.25e-06\n",
      "epoch: 91, train loss: 0.70655,  train_accuracy: 0.80669, test_accuracy 0.77332\n",
      "current LR: 6.25e-06\n",
      "epoch: 92, train loss: 0.73136,  train_accuracy: 0.80690, test_accuracy 0.77278\n",
      "current LR: 6.25e-06\n",
      "epoch: 93, train loss: 0.70459,  train_accuracy: 0.80618, test_accuracy 0.77309\n",
      "current LR: 6.25e-06\n",
      "epoch: 94, train loss: 0.78695,  train_accuracy: 0.80699, test_accuracy 0.77305\n",
      "current LR: 6.25e-06\n",
      "epoch: 95, train loss: 0.72902,  train_accuracy: 0.80706, test_accuracy 0.77336\n",
      "current LR: 6.25e-06\n",
      "epoch: 96, train loss: 0.77238,  train_accuracy: 0.80729, test_accuracy 0.77343\n",
      "current LR: 6.25e-06\n",
      "epoch: 97, train loss: 0.75765,  train_accuracy: 0.80596, test_accuracy 0.77305\n",
      "current LR: 6.25e-06\n",
      "epoch: 98, train loss: 0.76903,  train_accuracy: 0.80672, test_accuracy 0.77320\n",
      "current LR: 6.25e-06\n",
      "epoch: 99, train loss: 0.67851,  train_accuracy: 0.80684, test_accuracy 0.77313\n",
      "current LR: 1.5625e-06\n"
     ]
    }
   ],
   "source": [
    "model_name = 'byol'\n",
    "in_dist_data = 'svhn'\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048, in_dist_data=in_dist_data, train_epoch=100, init_lr=1e-4)\n",
    "torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_{in_dist_data}_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vit_base_patch16_384 no linear image net head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vit_base_patch16_384'\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=0).to(device)\n",
    "model.eval();\n",
    "model_name = 'vit_base_patch16_384_nohead'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "svhn_data_train = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform\n",
    ")\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_model = train_linear_model(model_name=model_name, device=device, emb_size=768)\n",
    "in_dist_data = 'svhn'\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=768, in_dist_data=in_dist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_{in_dist_data}_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vit_base_patch16_384 with 1000 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'vit_base_patch16_384'\n",
    "model = timm.create_model(model_name, pretrained=True, ).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "imagenet_sanity_check(model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "svhn_data_train = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform\n",
    ")\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax ImageNet resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_model = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "soft_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/workspaces/ood/data/models/torch/hub/checkpoints/resnet50-0676ba61.pth\"\n",
    "    )\n",
    ")\n",
    "summary(soft_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import imagenet_sanity_check\n",
    "\n",
    "imagenet_sanity_check(soft_model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(soft_model, cifar_data_train, \"soft_cifar_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"soft\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/soft_cifar_linear_model0.88test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCo v2 ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_moco\n",
    "\n",
    "model = load_moco(\"/workspaces/ood/data/models/moco_v2_800ep_pretrain.pth.tar\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import add_labels, predict_on_whole_dataset_moco\n",
    "\n",
    "predict_on_whole_dataset_moco(model, cifar_data_test, \"moco_cifar_test\", device)\n",
    "predict_on_whole_dataset_moco(model, cifar_data_train, \"moco_cifar_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_train, \"moco_svhn_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_test, \"moco_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"moco\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/moco_cifar_linear_model0.8382test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_byol\n",
    "\n",
    "model = load_byol(\"/workspaces/ood/data/models/pretrain_res50x1.pth.tar\", device)\n",
    "\n",
    "model_name = \"byol\"\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"byol\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model0.905test_accuracy.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
