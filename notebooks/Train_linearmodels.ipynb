{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from scripts_ood.train import train_linear_model\n",
    "import warnings\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/workspaces/ood/\")\n",
    "from pytorch_pretrained_vit import ViT\n",
    "\n",
    "from scripts_ood.utils import load_pretrained_weights_vit\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device = torch.device(\"cuda\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# transform = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.Resize(256),\n",
    "#         transforms.CenterCrop(224),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vit_base_patch16_384 with 1000 head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "\n",
    "model_name = 'vit_base_patch16_384'\n",
    "model = timm.create_model(model_name, pretrained=True, ).to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"282: 'tiger cat'\", \"281: 'tabby, tabby cat',model_pre\", \"285: 'Egyptian cat'\", \"287: 'lynx, catamount'\", \"288: 'leopard, Panthera pardus'\", \"292: 'tiger, Panthera tigris'\", \"290: 'jaguar, panther, Panthera onca, Felis onca'\", \"289: 'snow leopard, ounce, Panthera uncia'\", \"284: 'Siamese cat, Siamese'\", \"286: 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'\"]\n"
     ]
    }
   ],
   "source": [
    "from scripts_ood.utils import imagenet_sanity_check\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "imagenet_sanity_check(model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data_train = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform\n",
    ")\n",
    "cifar_data_test = torchvision.datasets.CIFAR10(\n",
    "    \"../data/cifar10\", download=False, transform=transform, train=False\n",
    ")\n",
    "\n",
    "svhn_data_train = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform\n",
    ")\n",
    "svhn_data_test = torchvision.datasets.SVHN(\n",
    "    \"../data/svhn\", download=False, transform=transform, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26032/26032 [11:16<00:00, 38.48it/s]\n",
      "100%|██████████| 10000/10000 [04:24<00:00, 37.78it/s]\n",
      "100%|██████████| 50000/50000 [21:58<00:00, 37.92it/s]  \n"
     ]
    }
   ],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 2.66225,  train_accuracy: 0.13706, test_accuracy 0.13350\n",
      "current LR: 0.0001\n",
      "epoch: 1, train loss: 0.55760,  train_accuracy: 0.95226, test_accuracy 0.95030\n",
      "current LR: 0.0001\n",
      "epoch: 2, train loss: 0.47813,  train_accuracy: 0.96536, test_accuracy 0.96400\n",
      "current LR: 0.0001\n",
      "epoch: 3, train loss: 0.42673,  train_accuracy: 0.96996, test_accuracy 0.96760\n",
      "current LR: 0.0001\n",
      "epoch: 4, train loss: 0.43435,  train_accuracy: 0.97304, test_accuracy 0.97130\n",
      "current LR: 0.0001\n",
      "epoch: 5, train loss: 0.43720,  train_accuracy: 0.97448, test_accuracy 0.97290\n",
      "current LR: 0.0001\n",
      "epoch: 6, train loss: 0.39485,  train_accuracy: 0.97592, test_accuracy 0.97370\n",
      "current LR: 0.0001\n",
      "epoch: 7, train loss: 0.39622,  train_accuracy: 0.97628, test_accuracy 0.97500\n",
      "current LR: 0.0001\n",
      "epoch: 8, train loss: 0.37443,  train_accuracy: 0.97732, test_accuracy 0.97500\n",
      "current LR: 0.0001\n",
      "epoch: 9, train loss: 0.34467,  train_accuracy: 0.97800, test_accuracy 0.97520\n",
      "current LR: 0.0001\n",
      "epoch: 10, train loss: 0.34653,  train_accuracy: 0.97792, test_accuracy 0.97550\n",
      "current LR: 0.0001\n",
      "epoch: 11, train loss: 0.33020,  train_accuracy: 0.97814, test_accuracy 0.97600\n",
      "current LR: 0.0001\n",
      "epoch: 12, train loss: 0.33145,  train_accuracy: 0.97924, test_accuracy 0.97680\n",
      "current LR: 0.0001\n",
      "epoch: 13, train loss: 0.33222,  train_accuracy: 0.97880, test_accuracy 0.97640\n",
      "current LR: 0.0001\n",
      "epoch: 14, train loss: 0.32119,  train_accuracy: 0.97982, test_accuracy 0.97650\n",
      "current LR: 0.0001\n",
      "epoch: 15, train loss: 0.33511,  train_accuracy: 0.97954, test_accuracy 0.97710\n",
      "current LR: 0.0001\n",
      "epoch: 16, train loss: 0.31929,  train_accuracy: 0.97966, test_accuracy 0.97750\n",
      "current LR: 0.0001\n",
      "epoch: 17, train loss: 0.29928,  train_accuracy: 0.98036, test_accuracy 0.97740\n",
      "current LR: 0.0001\n",
      "epoch: 18, train loss: 0.29085,  train_accuracy: 0.98062, test_accuracy 0.97730\n",
      "current LR: 0.0001\n",
      "epoch: 19, train loss: 0.28926,  train_accuracy: 0.98062, test_accuracy 0.97780\n",
      "current LR: 2.5e-05\n",
      "epoch: 20, train loss: 0.30005,  train_accuracy: 0.98038, test_accuracy 0.97830\n",
      "current LR: 5e-05\n",
      "epoch: 21, train loss: 0.31015,  train_accuracy: 0.98124, test_accuracy 0.97710\n",
      "current LR: 5e-05\n",
      "epoch: 22, train loss: 0.27664,  train_accuracy: 0.98122, test_accuracy 0.97790\n",
      "current LR: 5e-05\n",
      "epoch: 23, train loss: 0.27304,  train_accuracy: 0.98128, test_accuracy 0.97800\n",
      "current LR: 5e-05\n",
      "epoch: 24, train loss: 0.26059,  train_accuracy: 0.98094, test_accuracy 0.97790\n",
      "current LR: 5e-05\n",
      "epoch: 25, train loss: 0.26498,  train_accuracy: 0.98144, test_accuracy 0.97820\n",
      "current LR: 5e-05\n",
      "epoch: 26, train loss: 0.27413,  train_accuracy: 0.98162, test_accuracy 0.97800\n",
      "current LR: 5e-05\n",
      "epoch: 27, train loss: 0.27115,  train_accuracy: 0.98172, test_accuracy 0.97820\n",
      "current LR: 5e-05\n",
      "epoch: 28, train loss: 0.26009,  train_accuracy: 0.98202, test_accuracy 0.97810\n",
      "current LR: 5e-05\n",
      "epoch: 29, train loss: 0.27567,  train_accuracy: 0.98166, test_accuracy 0.97860\n",
      "current LR: 5e-05\n",
      "epoch: 30, train loss: 0.25567,  train_accuracy: 0.98142, test_accuracy 0.97810\n",
      "current LR: 5e-05\n",
      "epoch: 31, train loss: 0.26572,  train_accuracy: 0.98188, test_accuracy 0.97830\n",
      "current LR: 5e-05\n",
      "epoch: 32, train loss: 0.26387,  train_accuracy: 0.98182, test_accuracy 0.97820\n",
      "current LR: 5e-05\n",
      "epoch: 33, train loss: 0.24231,  train_accuracy: 0.98204, test_accuracy 0.97860\n",
      "current LR: 5e-05\n",
      "epoch: 34, train loss: 0.28465,  train_accuracy: 0.98200, test_accuracy 0.97820\n",
      "current LR: 5e-05\n",
      "epoch: 35, train loss: 0.24198,  train_accuracy: 0.98182, test_accuracy 0.97900\n",
      "current LR: 5e-05\n",
      "epoch: 36, train loss: 0.26848,  train_accuracy: 0.98214, test_accuracy 0.97840\n",
      "current LR: 5e-05\n",
      "epoch: 37, train loss: 0.24147,  train_accuracy: 0.98216, test_accuracy 0.97830\n",
      "current LR: 5e-05\n",
      "epoch: 38, train loss: 0.24675,  train_accuracy: 0.98236, test_accuracy 0.97850\n",
      "current LR: 5e-05\n",
      "epoch: 39, train loss: 0.24541,  train_accuracy: 0.98208, test_accuracy 0.97940\n",
      "current LR: 1.25e-05\n",
      "epoch: 40, train loss: 0.24727,  train_accuracy: 0.98238, test_accuracy 0.97850\n",
      "current LR: 2.5e-05\n",
      "epoch: 41, train loss: 0.23161,  train_accuracy: 0.98264, test_accuracy 0.97890\n",
      "current LR: 2.5e-05\n",
      "epoch: 42, train loss: 0.21411,  train_accuracy: 0.98258, test_accuracy 0.97880\n",
      "current LR: 2.5e-05\n",
      "epoch: 43, train loss: 0.23738,  train_accuracy: 0.98272, test_accuracy 0.97910\n",
      "current LR: 2.5e-05\n",
      "epoch: 44, train loss: 0.22396,  train_accuracy: 0.98232, test_accuracy 0.97910\n",
      "current LR: 2.5e-05\n",
      "epoch: 45, train loss: 0.23098,  train_accuracy: 0.98240, test_accuracy 0.97890\n",
      "current LR: 2.5e-05\n",
      "epoch: 46, train loss: 0.24202,  train_accuracy: 0.98256, test_accuracy 0.97890\n",
      "current LR: 2.5e-05\n",
      "epoch: 47, train loss: 0.24536,  train_accuracy: 0.98248, test_accuracy 0.97880\n",
      "current LR: 2.5e-05\n",
      "epoch: 48, train loss: 0.24388,  train_accuracy: 0.98276, test_accuracy 0.97900\n",
      "current LR: 2.5e-05\n",
      "epoch: 49, train loss: 0.23038,  train_accuracy: 0.98290, test_accuracy 0.97870\n",
      "current LR: 2.5e-05\n",
      "epoch: 50, train loss: 0.21306,  train_accuracy: 0.98278, test_accuracy 0.97930\n",
      "current LR: 2.5e-05\n",
      "epoch: 51, train loss: 0.23755,  train_accuracy: 0.98248, test_accuracy 0.97940\n",
      "current LR: 2.5e-05\n",
      "epoch: 52, train loss: 0.21753,  train_accuracy: 0.98262, test_accuracy 0.97940\n",
      "current LR: 2.5e-05\n",
      "epoch: 53, train loss: 0.21603,  train_accuracy: 0.98264, test_accuracy 0.97930\n",
      "current LR: 2.5e-05\n",
      "epoch: 54, train loss: 0.22596,  train_accuracy: 0.98286, test_accuracy 0.97980\n",
      "current LR: 2.5e-05\n",
      "epoch: 55, train loss: 0.21947,  train_accuracy: 0.98260, test_accuracy 0.97870\n",
      "current LR: 2.5e-05\n",
      "epoch: 56, train loss: 0.22773,  train_accuracy: 0.98292, test_accuracy 0.97920\n",
      "current LR: 2.5e-05\n",
      "epoch: 57, train loss: 0.20911,  train_accuracy: 0.98250, test_accuracy 0.97920\n",
      "current LR: 2.5e-05\n",
      "epoch: 58, train loss: 0.24130,  train_accuracy: 0.98266, test_accuracy 0.97980\n",
      "current LR: 2.5e-05\n",
      "epoch: 59, train loss: 0.22433,  train_accuracy: 0.98296, test_accuracy 0.97910\n",
      "current LR: 6.25e-06\n",
      "epoch: 60, train loss: 0.19886,  train_accuracy: 0.98304, test_accuracy 0.97930\n",
      "current LR: 1.25e-05\n",
      "epoch: 61, train loss: 0.22456,  train_accuracy: 0.98288, test_accuracy 0.97950\n",
      "current LR: 1.25e-05\n",
      "epoch: 62, train loss: 0.22058,  train_accuracy: 0.98276, test_accuracy 0.97930\n",
      "current LR: 1.25e-05\n",
      "epoch: 63, train loss: 0.21469,  train_accuracy: 0.98318, test_accuracy 0.98000\n",
      "current LR: 1.25e-05\n",
      "epoch: 64, train loss: 0.19792,  train_accuracy: 0.98318, test_accuracy 0.97970\n",
      "current LR: 1.25e-05\n",
      "epoch: 65, train loss: 0.20267,  train_accuracy: 0.98302, test_accuracy 0.97940\n",
      "current LR: 1.25e-05\n",
      "epoch: 66, train loss: 0.23509,  train_accuracy: 0.98302, test_accuracy 0.97940\n",
      "current LR: 1.25e-05\n",
      "epoch: 67, train loss: 0.21465,  train_accuracy: 0.98308, test_accuracy 0.97930\n",
      "current LR: 1.25e-05\n",
      "epoch: 68, train loss: 0.22443,  train_accuracy: 0.98320, test_accuracy 0.97970\n",
      "current LR: 1.25e-05\n",
      "epoch: 69, train loss: 0.22116,  train_accuracy: 0.98292, test_accuracy 0.97930\n",
      "current LR: 1.25e-05\n",
      "epoch: 70, train loss: 0.19289,  train_accuracy: 0.98262, test_accuracy 0.97950\n",
      "current LR: 1.25e-05\n",
      "epoch: 71, train loss: 0.23038,  train_accuracy: 0.98300, test_accuracy 0.97930\n",
      "current LR: 1.25e-05\n",
      "epoch: 72, train loss: 0.22030,  train_accuracy: 0.98314, test_accuracy 0.97950\n",
      "current LR: 1.25e-05\n",
      "epoch: 73, train loss: 0.20175,  train_accuracy: 0.98306, test_accuracy 0.97980\n",
      "current LR: 1.25e-05\n",
      "epoch: 74, train loss: 0.20974,  train_accuracy: 0.98340, test_accuracy 0.97920\n",
      "current LR: 1.25e-05\n",
      "epoch: 75, train loss: 0.21738,  train_accuracy: 0.98324, test_accuracy 0.97940\n",
      "current LR: 1.25e-05\n",
      "epoch: 76, train loss: 0.21507,  train_accuracy: 0.98298, test_accuracy 0.97970\n",
      "current LR: 1.25e-05\n",
      "epoch: 77, train loss: 0.21283,  train_accuracy: 0.98332, test_accuracy 0.97960\n",
      "current LR: 1.25e-05\n",
      "epoch: 78, train loss: 0.19940,  train_accuracy: 0.98316, test_accuracy 0.97970\n",
      "current LR: 1.25e-05\n",
      "epoch: 79, train loss: 0.20384,  train_accuracy: 0.98308, test_accuracy 0.97970\n",
      "current LR: 3.125e-06\n",
      "epoch: 80, train loss: 0.19971,  train_accuracy: 0.98290, test_accuracy 0.97890\n",
      "current LR: 6.25e-06\n",
      "epoch: 81, train loss: 0.21299,  train_accuracy: 0.98334, test_accuracy 0.97960\n",
      "current LR: 6.25e-06\n",
      "epoch: 82, train loss: 0.21091,  train_accuracy: 0.98320, test_accuracy 0.97950\n",
      "current LR: 6.25e-06\n",
      "epoch: 83, train loss: 0.20315,  train_accuracy: 0.98354, test_accuracy 0.97960\n",
      "current LR: 6.25e-06\n",
      "epoch: 84, train loss: 0.19324,  train_accuracy: 0.98324, test_accuracy 0.97940\n",
      "current LR: 6.25e-06\n",
      "epoch: 85, train loss: 0.22241,  train_accuracy: 0.98310, test_accuracy 0.97970\n",
      "current LR: 6.25e-06\n",
      "epoch: 86, train loss: 0.21549,  train_accuracy: 0.98310, test_accuracy 0.97940\n",
      "current LR: 6.25e-06\n",
      "epoch: 87, train loss: 0.20708,  train_accuracy: 0.98314, test_accuracy 0.97960\n",
      "current LR: 6.25e-06\n",
      "epoch: 88, train loss: 0.21115,  train_accuracy: 0.98342, test_accuracy 0.97960\n",
      "current LR: 6.25e-06\n",
      "epoch: 89, train loss: 0.21683,  train_accuracy: 0.98356, test_accuracy 0.97940\n",
      "current LR: 6.25e-06\n",
      "epoch: 90, train loss: 0.19559,  train_accuracy: 0.98352, test_accuracy 0.97950\n",
      "current LR: 6.25e-06\n",
      "epoch: 91, train loss: 0.20062,  train_accuracy: 0.98354, test_accuracy 0.97950\n",
      "current LR: 6.25e-06\n",
      "epoch: 92, train loss: 0.19370,  train_accuracy: 0.98362, test_accuracy 0.97960\n",
      "current LR: 6.25e-06\n",
      "epoch: 93, train loss: 0.21477,  train_accuracy: 0.98348, test_accuracy 0.97970\n",
      "current LR: 6.25e-06\n",
      "epoch: 94, train loss: 0.19619,  train_accuracy: 0.98330, test_accuracy 0.97980\n",
      "current LR: 6.25e-06\n",
      "epoch: 95, train loss: 0.18793,  train_accuracy: 0.98322, test_accuracy 0.97970\n",
      "current LR: 6.25e-06\n",
      "epoch: 96, train loss: 0.21130,  train_accuracy: 0.98310, test_accuracy 0.97960\n",
      "current LR: 6.25e-06\n",
      "epoch: 97, train loss: 0.20058,  train_accuracy: 0.98312, test_accuracy 0.97980\n",
      "current LR: 6.25e-06\n",
      "epoch: 98, train loss: 0.18352,  train_accuracy: 0.98320, test_accuracy 0.97990\n",
      "current LR: 6.25e-06\n",
      "epoch: 99, train loss: 0.21262,  train_accuracy: 0.98322, test_accuracy 0.97950\n",
      "current LR: 1.5625e-06\n",
      "epoch: 100, train loss: 0.21349,  train_accuracy: 0.98314, test_accuracy 0.97950\n",
      "current LR: 3.125e-06\n",
      "epoch: 101, train loss: 0.22722,  train_accuracy: 0.98350, test_accuracy 0.97970\n",
      "current LR: 3.125e-06\n",
      "epoch: 102, train loss: 0.20364,  train_accuracy: 0.98326, test_accuracy 0.97990\n",
      "current LR: 3.125e-06\n",
      "epoch: 103, train loss: 0.18486,  train_accuracy: 0.98338, test_accuracy 0.97950\n",
      "current LR: 3.125e-06\n",
      "epoch: 104, train loss: 0.23243,  train_accuracy: 0.98334, test_accuracy 0.97960\n",
      "current LR: 3.125e-06\n",
      "epoch: 105, train loss: 0.21137,  train_accuracy: 0.98342, test_accuracy 0.97970\n",
      "current LR: 3.125e-06\n",
      "epoch: 106, train loss: 0.18168,  train_accuracy: 0.98362, test_accuracy 0.97940\n",
      "current LR: 3.125e-06\n",
      "epoch: 107, train loss: 0.21469,  train_accuracy: 0.98320, test_accuracy 0.97960\n",
      "current LR: 3.125e-06\n",
      "epoch: 108, train loss: 0.20818,  train_accuracy: 0.98358, test_accuracy 0.97950\n",
      "current LR: 3.125e-06\n",
      "epoch: 109, train loss: 0.19501,  train_accuracy: 0.98346, test_accuracy 0.97970\n",
      "current LR: 3.125e-06\n",
      "epoch: 110, train loss: 0.19759,  train_accuracy: 0.98300, test_accuracy 0.97960\n",
      "current LR: 3.125e-06\n",
      "epoch: 111, train loss: 0.21287,  train_accuracy: 0.98284, test_accuracy 0.97960\n",
      "current LR: 3.125e-06\n",
      "epoch: 112, train loss: 0.19006,  train_accuracy: 0.98344, test_accuracy 0.97940\n",
      "current LR: 3.125e-06\n",
      "epoch: 113, train loss: 0.17953,  train_accuracy: 0.98346, test_accuracy 0.97970\n",
      "current LR: 3.125e-06\n",
      "epoch: 114, train loss: 0.21457,  train_accuracy: 0.98378, test_accuracy 0.97950\n",
      "current LR: 3.125e-06\n",
      "epoch: 115, train loss: 0.19886,  train_accuracy: 0.98376, test_accuracy 0.97950\n",
      "current LR: 3.125e-06\n",
      "epoch: 116, train loss: 0.21293,  train_accuracy: 0.98340, test_accuracy 0.97960\n",
      "current LR: 3.125e-06\n",
      "epoch: 117, train loss: 0.21400,  train_accuracy: 0.98326, test_accuracy 0.97950\n",
      "current LR: 3.125e-06\n",
      "epoch: 118, train loss: 0.20212,  train_accuracy: 0.98316, test_accuracy 0.97980\n",
      "current LR: 3.125e-06\n",
      "epoch: 119, train loss: 0.19252,  train_accuracy: 0.98300, test_accuracy 0.97990\n",
      "current LR: 7.8125e-07\n",
      "epoch: 120, train loss: 0.20505,  train_accuracy: 0.98386, test_accuracy 0.97990\n",
      "current LR: 1.5625e-06\n",
      "epoch: 121, train loss: 0.19562,  train_accuracy: 0.98366, test_accuracy 0.97940\n",
      "current LR: 1.5625e-06\n",
      "epoch: 122, train loss: 0.20216,  train_accuracy: 0.98334, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 123, train loss: 0.19928,  train_accuracy: 0.98388, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 124, train loss: 0.20681,  train_accuracy: 0.98334, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 125, train loss: 0.19296,  train_accuracy: 0.98368, test_accuracy 0.97970\n",
      "current LR: 1.5625e-06\n",
      "epoch: 126, train loss: 0.21403,  train_accuracy: 0.98362, test_accuracy 0.97970\n",
      "current LR: 1.5625e-06\n",
      "epoch: 127, train loss: 0.19280,  train_accuracy: 0.98338, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 128, train loss: 0.19949,  train_accuracy: 0.98296, test_accuracy 0.97970\n",
      "current LR: 1.5625e-06\n",
      "epoch: 129, train loss: 0.19848,  train_accuracy: 0.98362, test_accuracy 0.97960\n",
      "current LR: 1.5625e-06\n",
      "epoch: 130, train loss: 0.18920,  train_accuracy: 0.98346, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 131, train loss: 0.19346,  train_accuracy: 0.98312, test_accuracy 0.97970\n",
      "current LR: 1.5625e-06\n",
      "epoch: 132, train loss: 0.20341,  train_accuracy: 0.98320, test_accuracy 0.97960\n",
      "current LR: 1.5625e-06\n",
      "epoch: 133, train loss: 0.20288,  train_accuracy: 0.98356, test_accuracy 0.97950\n",
      "current LR: 1.5625e-06\n",
      "epoch: 134, train loss: 0.20187,  train_accuracy: 0.98354, test_accuracy 0.97970\n",
      "current LR: 1.5625e-06\n",
      "epoch: 135, train loss: 0.20252,  train_accuracy: 0.98350, test_accuracy 0.97960\n",
      "current LR: 1.5625e-06\n",
      "epoch: 136, train loss: 0.20048,  train_accuracy: 0.98346, test_accuracy 0.97970\n",
      "current LR: 1.5625e-06\n",
      "epoch: 137, train loss: 0.19245,  train_accuracy: 0.98366, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 138, train loss: 0.21199,  train_accuracy: 0.98350, test_accuracy 0.97980\n",
      "current LR: 1.5625e-06\n",
      "epoch: 139, train loss: 0.22571,  train_accuracy: 0.98354, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 140, train loss: 0.20470,  train_accuracy: 0.98398, test_accuracy 0.97980\n",
      "current LR: 7.8125e-07\n",
      "epoch: 141, train loss: 0.18797,  train_accuracy: 0.98356, test_accuracy 0.97980\n",
      "current LR: 7.8125e-07\n",
      "epoch: 142, train loss: 0.19858,  train_accuracy: 0.98356, test_accuracy 0.97970\n",
      "current LR: 7.8125e-07\n",
      "epoch: 143, train loss: 0.19413,  train_accuracy: 0.98338, test_accuracy 0.97970\n",
      "current LR: 7.8125e-07\n",
      "epoch: 144, train loss: 0.20237,  train_accuracy: 0.98368, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 145, train loss: 0.19681,  train_accuracy: 0.98352, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 146, train loss: 0.22069,  train_accuracy: 0.98362, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 147, train loss: 0.19060,  train_accuracy: 0.98294, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 148, train loss: 0.19960,  train_accuracy: 0.98322, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 149, train loss: 0.19374,  train_accuracy: 0.98344, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 150, train loss: 0.19311,  train_accuracy: 0.98390, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 151, train loss: 0.18127,  train_accuracy: 0.98362, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 152, train loss: 0.19792,  train_accuracy: 0.98374, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 153, train loss: 0.20164,  train_accuracy: 0.98342, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 154, train loss: 0.19130,  train_accuracy: 0.98322, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 155, train loss: 0.20283,  train_accuracy: 0.98318, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 156, train loss: 0.20314,  train_accuracy: 0.98324, test_accuracy 0.97970\n",
      "current LR: 7.8125e-07\n",
      "epoch: 157, train loss: 0.22285,  train_accuracy: 0.98342, test_accuracy 0.97960\n",
      "current LR: 7.8125e-07\n",
      "epoch: 158, train loss: 0.22021,  train_accuracy: 0.98332, test_accuracy 0.97980\n",
      "current LR: 7.8125e-07\n",
      "epoch: 159, train loss: 0.19390,  train_accuracy: 0.98334, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 160, train loss: 0.17979,  train_accuracy: 0.98370, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 161, train loss: 0.20427,  train_accuracy: 0.98374, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 162, train loss: 0.20257,  train_accuracy: 0.98340, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 163, train loss: 0.20200,  train_accuracy: 0.98384, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 164, train loss: 0.19816,  train_accuracy: 0.98348, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 165, train loss: 0.21359,  train_accuracy: 0.98340, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 166, train loss: 0.21424,  train_accuracy: 0.98348, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 167, train loss: 0.19295,  train_accuracy: 0.98334, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 168, train loss: 0.19307,  train_accuracy: 0.98356, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 169, train loss: 0.21102,  train_accuracy: 0.98378, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 170, train loss: 0.20712,  train_accuracy: 0.98360, test_accuracy 0.97970\n",
      "current LR: 3.90625e-07\n",
      "epoch: 171, train loss: 0.19326,  train_accuracy: 0.98336, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 172, train loss: 0.19486,  train_accuracy: 0.98366, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 173, train loss: 0.20579,  train_accuracy: 0.98356, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 174, train loss: 0.20752,  train_accuracy: 0.98372, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 175, train loss: 0.18706,  train_accuracy: 0.98348, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 176, train loss: 0.20189,  train_accuracy: 0.98360, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 177, train loss: 0.19216,  train_accuracy: 0.98340, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 178, train loss: 0.20187,  train_accuracy: 0.98342, test_accuracy 0.97980\n",
      "current LR: 3.90625e-07\n",
      "epoch: 179, train loss: 0.19946,  train_accuracy: 0.98370, test_accuracy 0.97980\n",
      "current LR: 9.765625e-08\n",
      "epoch: 180, train loss: 0.20232,  train_accuracy: 0.98352, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 181, train loss: 0.20613,  train_accuracy: 0.98364, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 182, train loss: 0.21075,  train_accuracy: 0.98372, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 183, train loss: 0.20327,  train_accuracy: 0.98358, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 184, train loss: 0.22441,  train_accuracy: 0.98364, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 185, train loss: 0.20766,  train_accuracy: 0.98330, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 186, train loss: 0.20052,  train_accuracy: 0.98358, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 187, train loss: 0.21223,  train_accuracy: 0.98384, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 188, train loss: 0.20103,  train_accuracy: 0.98346, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 189, train loss: 0.21794,  train_accuracy: 0.98348, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 190, train loss: 0.20222,  train_accuracy: 0.98322, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 191, train loss: 0.20006,  train_accuracy: 0.98400, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 192, train loss: 0.20442,  train_accuracy: 0.98372, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 193, train loss: 0.19673,  train_accuracy: 0.98366, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 194, train loss: 0.21348,  train_accuracy: 0.98362, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 195, train loss: 0.19860,  train_accuracy: 0.98328, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 196, train loss: 0.18634,  train_accuracy: 0.98312, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 197, train loss: 0.20072,  train_accuracy: 0.98384, test_accuracy 0.97980\n",
      "current LR: 1.953125e-07\n",
      "epoch: 198, train loss: 0.19873,  train_accuracy: 0.98340, test_accuracy 0.97970\n",
      "current LR: 1.953125e-07\n",
      "epoch: 199, train loss: 0.20722,  train_accuracy: 0.98372, test_accuracy 0.97970\n",
      "current LR: 4.8828125e-08\n"
     ]
    }
   ],
   "source": [
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax ImageNet resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_model = torchvision.models.resnet50(pretrained=False).to(device)\n",
    "soft_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/workspaces/ood/data/models/torch/hub/checkpoints/resnet50-0676ba61.pth\"\n",
    "    )\n",
    ")\n",
    "summary(soft_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import imagenet_sanity_check\n",
    "\n",
    "imagenet_sanity_check(soft_model, transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_ood.utils import add_labels, predict_on_whole_dataset\n",
    "\n",
    "predict_on_whole_dataset(soft_model, cifar_data_train, \"soft_cifar_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"soft\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/soft_cifar_linear_model0.88test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCo v2 ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_moco\n",
    "\n",
    "model = load_moco(\"/workspaces/ood/data/models/moco_v2_800ep_pretrain.pth.tar\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import add_labels, predict_on_whole_dataset_moco\n",
    "\n",
    "predict_on_whole_dataset_moco(model, cifar_data_test, \"moco_cifar_test\", device)\n",
    "predict_on_whole_dataset_moco(model, cifar_data_train, \"moco_cifar_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_train, \"moco_svhn_train\", device)\n",
    "predict_on_whole_dataset_moco(model, svhn_data_test, \"moco_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"moco\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/moco_cifar_linear_model0.8382test_accuracy.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BYOL ImageNet pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ood.utils import load_byol\n",
    "\n",
    "model = load_byol(\"/workspaces/ood/data/models/pretrain_res50x1.pth.tar\", device)\n",
    "\n",
    "model_name = \"byol\"\n",
    "predict_on_whole_dataset(model, cifar_data_test, f\"{model_name}_cifar_test\", device)\n",
    "predict_on_whole_dataset(model, cifar_data_train, f\"{model_name}_cifar_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_train, f\"{model_name}_svhn_train\", device)\n",
    "predict_on_whole_dataset(model, svhn_data_test, f\"{model_name}_svhn_test\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"byol\"\n",
    "\n",
    "linear_model = train_linear_model(model_name=model_name, device=device, emb_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(linear_model.state_dict(), f'../data/trained_models/{model_name}_cifar_linear_model0.905test_accuracy.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
